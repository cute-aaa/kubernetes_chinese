# 监视、日志记录和调试

## （未翻译）应用程序内部排查和调试

Once your application is running, you’ll inevitably need to debug problems with it. Earlier we described how you can use `kubectl get pods` to retrieve simple status information about your pods. But there are a number of ways to get even more information about your application.

### Using `kubectl describe pod` to fetch details about pods

For this example we’ll use a Deployment to create two pods, similar to the earlier example.



```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 80
```

Create deployment by running following command:

```shell
kubectl apply -f https://k8s.io/examples/application/nginx-with-request.yaml
deployment.apps/nginx-deployment created
```

Check pod status by following command:

```shell
kubectl get pods
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1006230814-6winp   1/1       Running   0          11s
nginx-deployment-1006230814-fmgu3   1/1       Running   0          11s
```

We can retrieve a lot more information about each of these pods using `kubectl describe pod`. For example:

```shell
kubectl describe pod nginx-deployment-1006230814-6winp
Name:		nginx-deployment-1006230814-6winp
Namespace:	default
Node:		kubernetes-node-wul5/10.240.0.9
Start Time:	Thu, 24 Mar 2016 01:39:49 +0000
Labels:		app=nginx,pod-template-hash=1006230814
Annotations:    kubernetes.io/created-by={"kind":"SerializedReference","apiVersion":"v1","reference":{"kind":"ReplicaSet","namespace":"default","name":"nginx-deployment-1956810328","uid":"14e607e7-8ba1-11e7-b5cb-fa16" ...
Status:		Running
IP:		10.244.0.6
Controllers:	ReplicaSet/nginx-deployment-1006230814
Containers:
  nginx:
    Container ID:	docker://90315cc9f513c724e9957a4788d3e625a078de84750f244a40f97ae355eb1149
    Image:		nginx
    Image ID:		docker://6f62f48c4e55d700cf3eb1b5e33fa051802986b77b874cc351cce539e5163707
    Port:		80/TCP
    QoS Tier:
      cpu:	Guaranteed
      memory:	Guaranteed
    Limits:
      cpu:	500m
      memory:	128Mi
    Requests:
      memory:		128Mi
      cpu:		500m
    State:		Running
      Started:		Thu, 24 Mar 2016 01:39:51 +0000
    Ready:		True
    Restart Count:	0
    Environment:        <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5kdvl (ro)
Conditions:
  Type          Status
  Initialized   True
  Ready         True
  PodScheduled  True
Volumes:
  default-token-4bcbi:
    Type:	Secret (a volume populated by a Secret)
    SecretName:	default-token-4bcbi
    Optional:   false
QoS Class:      Guaranteed
Node-Selectors: <none>
Tolerations:    <none>
Events:
  FirstSeen	LastSeen	Count	From					SubobjectPath		Type		Reason		Message
  ---------	--------	-----	----					-------------		--------	------		-------
  54s		54s		1	{default-scheduler }						Normal		Scheduled	Successfully assigned nginx-deployment-1006230814-6winp to kubernetes-node-wul5
  54s		54s		1	{kubelet kubernetes-node-wul5}	spec.containers{nginx}	Normal		Pulling		pulling image "nginx"
  53s		53s		1	{kubelet kubernetes-node-wul5}	spec.containers{nginx}	Normal		Pulled		Successfully pulled image "nginx"
  53s		53s		1	{kubelet kubernetes-node-wul5}	spec.containers{nginx}	Normal		Created		Created container with docker id 90315cc9f513
  53s		53s		1	{kubelet kubernetes-node-wul5}	spec.containers{nginx}	Normal		Started		Started container with docker id 90315cc9f513
```

Here you can see configuration information about the container(s) and Pod (labels, resource requirements, etc.), as well as status information about the container(s) and Pod (state, readiness, restart count, events, etc.).

The container state is one of Waiting, Running, or Terminated. Depending on the state, additional information will be provided – here you can see that for a container in Running state, the system tells you when the container started.

Ready tells you whether the container passed its last readiness probe. (In this case, the container does not have a readiness probe configured; the container is assumed to be ready if no readiness probe is configured.)

Restart Count tells you how many times the container has been restarted; this information can be useful for detecting crash loops in containers that are configured with a restart policy of ‘always.’

Currently the only Condition associated with a Pod is the binary Ready condition, which indicates that the pod is able to service requests and should be added to the load balancing pools of all matching services.

Lastly, you see a log of recent events related to your Pod. The system compresses multiple identical events by indicating the first and last time it was seen and the number of times it was seen. “From” indicates the component that is logging the event, “SubobjectPath” tells you which object (e.g. container within the pod) is being referred to, and “Reason” and “Message” tell you what happened.

### Example: debugging Pending Pods

A common scenario that you can detect using events is when you’ve created a Pod that won’t fit on any node. For example, the Pod might request more resources than are free on any node, or it might specify a label selector that doesn’t match any nodes. Let’s say we created the previous Deployment with 5 replicas (instead of 2) and requesting 600 millicores instead of 500, on a four-node cluster where each (virtual) machine has 1 CPU. In that case one of the Pods will not be able to schedule. (Note that because of the cluster addon pods such as fluentd, skydns, etc., that run on each node, if we requested 1000 millicores then none of the Pods would be able to schedule.)

```shell
kubectl get pods
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1006230814-6winp   1/1       Running   0          7m
nginx-deployment-1006230814-fmgu3   1/1       Running   0          7m
nginx-deployment-1370807587-6ekbw   1/1       Running   0          1m
nginx-deployment-1370807587-fg172   0/1       Pending   0          1m
nginx-deployment-1370807587-fz9sd   0/1       Pending   0          1m
```

To find out why the nginx-deployment-1370807587-fz9sd pod is not running, we can use `kubectl describe pod` on the pending Pod and look at its events:

```shell
kubectl describe pod nginx-deployment-1370807587-fz9sd
  Name:		nginx-deployment-1370807587-fz9sd
  Namespace:	default
  Node:		/
  Labels:		app=nginx,pod-template-hash=1370807587
  Status:		Pending
  IP:
  Controllers:	ReplicaSet/nginx-deployment-1370807587
  Containers:
    nginx:
      Image:	nginx
      Port:	80/TCP
      QoS Tier:
        memory:	Guaranteed
        cpu:	Guaranteed
      Limits:
        cpu:	1
        memory:	128Mi
      Requests:
        cpu:	1
        memory:	128Mi
      Environment Variables:
  Volumes:
    default-token-4bcbi:
      Type:	Secret (a volume populated by a Secret)
      SecretName:	default-token-4bcbi
  Events:
    FirstSeen	LastSeen	Count	From			        SubobjectPath	Type		Reason			    Message
    ---------	--------	-----	----			        -------------	--------	------			    -------
    1m		    48s		    7	    {default-scheduler }			        Warning		FailedScheduling	pod (nginx-deployment-1370807587-fz9sd) failed to fit in any node
  fit failure on node (kubernetes-node-6ta5): Node didn't have enough resource: CPU, requested: 1000, used: 1420, capacity: 2000
  fit failure on node (kubernetes-node-wul5): Node didn't have enough resource: CPU, requested: 1000, used: 1100, capacity: 2000
```

Here you can see the event generated by the scheduler saying that the Pod failed to schedule for reason `FailedScheduling` (and possibly others). The message tells us that there were not enough resources for the Pod on any of the nodes.

To correct this situation, you can use `kubectl scale` to update your Deployment to specify four or fewer replicas. (Or you could just leave the one Pod pending, which is harmless.)

Events such as the ones you saw at the end of `kubectl describe pod` are persisted in etcd and provide high-level information on what is happening in the cluster. To list all events you can use

```shell
kubectl get events
```

but you have to remember that events are namespaced. This means that if you’re interested in events for some namespaced object (e.g. what happened with Pods in namespace `my-namespace`) you need to explicitly provide a namespace to the command:

```shell
kubectl get events --namespace=my-namespace
```

To see events from all namespaces, you can use the `--all-namespaces` argument.

In addition to `kubectl describe pod`, another way to get extra information about a pod (beyond what is provided by `kubectl get pod`) is to pass the `-o yaml` output format flag to `kubectl get pod`. This will give you, in YAML format, even more information than `kubectl describe pod`–essentially all of the information the system has about the Pod. Here you will see things like annotations (which are key-value metadata without the label restrictions, that is used internally by Kubernetes system components), restart policy, ports, and volumes.

```shell
kubectl get pod nginx-deployment-1006230814-6winp -o yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubernetes.io/created-by: |
      {"kind":"SerializedReference","apiVersion":"v1","reference":{"kind":"ReplicaSet","namespace":"default","name":"nginx-deployment-1006230814","uid":"4c84c175-f161-11e5-9a78-42010af00005","apiVersion":"extensions","resourceVersion":"133434"}}
  creationTimestamp: 2016-03-24T01:39:50Z
  generateName: nginx-deployment-1006230814-
  labels:
    app: nginx
    pod-template-hash: "1006230814"
  name: nginx-deployment-1006230814-6winp
  namespace: default
  resourceVersion: "133447"
  selfLink: /api/v1/namespaces/default/pods/nginx-deployment-1006230814-6winp
  uid: 4c879808-f161-11e5-9a78-42010af00005
spec:
  containers:
  - image: nginx
    imagePullPolicy: Always
    name: nginx
    ports:
    - containerPort: 80
      protocol: TCP
    resources:
      limits:
        cpu: 500m
        memory: 128Mi
      requests:
        cpu: 500m
        memory: 128Mi
    terminationMessagePath: /dev/termination-log
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: default-token-4bcbi
      readOnly: true
  dnsPolicy: ClusterFirst
  nodeName: kubernetes-node-wul5
  restartPolicy: Always
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  volumes:
  - name: default-token-4bcbi
    secret:
      secretName: default-token-4bcbi
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: 2016-03-24T01:39:51Z
    status: "True"
    type: Ready
  containerStatuses:
  - containerID: docker://90315cc9f513c724e9957a4788d3e625a078de84750f244a40f97ae355eb1149
    image: nginx
    imageID: docker://6f62f48c4e55d700cf3eb1b5e33fa051802986b77b874cc351cce539e5163707
    lastState: {}
    name: nginx
    ready: true
    restartCount: 0
    state:
      running:
        startedAt: 2016-03-24T01:39:51Z
  hostIP: 10.240.0.9
  phase: Running
  podIP: 10.244.0.6
  startTime: 2016-03-24T01:39:49Z
```

### Example: debugging a down/unreachable node

Sometimes when debugging it can be useful to look at the status of a node – for example, because you’ve noticed strange behavior of a Pod that’s running on the node, or to find out why a Pod won’t schedule onto the node. As with Pods, you can use `kubectl describe node` and `kubectl get node -o yaml` to retrieve detailed information about nodes. For example, here’s what you’ll see if a node is down (disconnected from the network, or kubelet dies and won’t restart, etc.). Notice the events that show the node is NotReady, and also notice that the pods are no longer running (they are evicted after five minutes of NotReady status).

```shell
kubectl get nodes
NAME                     STATUS       ROLES     AGE     VERSION
kubernetes-node-861h     NotReady     <none>    1h      v1.13.0
kubernetes-node-bols     Ready        <none>    1h      v1.13.0
kubernetes-node-st6x     Ready        <none>    1h      v1.13.0
kubernetes-node-unaj     Ready        <none>    1h      v1.13.0
kubectl describe node kubernetes-node-861h
Name:			kubernetes-node-861h
Role
Labels:		 kubernetes.io/arch=amd64
           kubernetes.io/os=linux
           kubernetes.io/hostname=kubernetes-node-861h
Annotations:        node.alpha.kubernetes.io/ttl=0
                    volumes.kubernetes.io/controller-managed-attach-detach=true
Taints:             <none>
CreationTimestamp:	Mon, 04 Sep 2017 17:13:23 +0800
Phase:
Conditions:
  Type		Status		LastHeartbeatTime			LastTransitionTime			Reason					Message
  ----    ------    -----------------     ------------------      ------          -------
  OutOfDisk             Unknown         Fri, 08 Sep 2017 16:04:28 +0800         Fri, 08 Sep 2017 16:20:58 +0800         NodeStatusUnknown       Kubelet stopped posting node status.
  MemoryPressure        Unknown         Fri, 08 Sep 2017 16:04:28 +0800         Fri, 08 Sep 2017 16:20:58 +0800         NodeStatusUnknown       Kubelet stopped posting node status.
  DiskPressure          Unknown         Fri, 08 Sep 2017 16:04:28 +0800         Fri, 08 Sep 2017 16:20:58 +0800         NodeStatusUnknown       Kubelet stopped posting node status.
  Ready                 Unknown         Fri, 08 Sep 2017 16:04:28 +0800         Fri, 08 Sep 2017 16:20:58 +0800         NodeStatusUnknown       Kubelet stopped posting node status.
Addresses:	10.240.115.55,104.197.0.26
Capacity:
 cpu:           2
 hugePages:     0
 memory:        4046788Ki
 pods:          110
Allocatable:
 cpu:           1500m
 hugePages:     0
 memory:        1479263Ki
 pods:          110
System Info:
 Machine ID:                    8e025a21a4254e11b028584d9d8b12c4
 System UUID:                   349075D1-D169-4F25-9F2A-E886850C47E3
 Boot ID:                       5cd18b37-c5bd-4658-94e0-e436d3f110e0
 Kernel Version:                4.4.0-31-generic
 OS Image:                      Debian GNU/Linux 8 (jessie)
 Operating System:              linux
 Architecture:                  amd64
 Container Runtime Version:     docker://1.12.5
 Kubelet Version:               v1.6.9+a3d1dfa6f4335
 Kube-Proxy Version:            v1.6.9+a3d1dfa6f4335
ExternalID:                     15233045891481496305
Non-terminated Pods:            (9 in total)
  Namespace                     Name                                            CPU Requests    CPU Limits      Memory Requests Memory Limits
  ---------                     ----                                            ------------    ----------      --------------- -------------
......
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests  CPU Limits      Memory Requests         Memory Limits
  ------------  ----------      ---------------         -------------
  900m (60%)    2200m (146%)    1009286400 (66%)        5681286400 (375%)
Events:         <none>
kubectl get node kubernetes-node-861h -o yaml
apiVersion: v1
kind: Node
metadata:
  creationTimestamp: 2015-07-10T21:32:29Z
  labels:
    kubernetes.io/hostname: kubernetes-node-861h
  name: kubernetes-node-861h
  resourceVersion: "757"
  selfLink: /api/v1/nodes/kubernetes-node-861h
  uid: 2a69374e-274b-11e5-a234-42010af0d969
spec:
  externalID: "15233045891481496305"
  podCIDR: 10.244.0.0/24
  providerID: gce://striped-torus-760/us-central1-b/kubernetes-node-861h
status:
  addresses:
  - address: 10.240.115.55
    type: InternalIP
  - address: 104.197.0.26
    type: ExternalIP
  capacity:
    cpu: "1"
    memory: 3800808Ki
    pods: "100"
  conditions:
  - lastHeartbeatTime: 2015-07-10T21:34:32Z
    lastTransitionTime: 2015-07-10T21:35:15Z
    reason: Kubelet stopped posting node status.
    status: Unknown
    type: Ready
  nodeInfo:
    bootID: 4e316776-b40d-4f78-a4ea-ab0d73390897
    containerRuntimeVersion: docker://Unknown
    kernelVersion: 3.16.0-0.bpo.4-amd64
    kubeProxyVersion: v0.21.1-185-gffc5a86098dc01
    kubeletVersion: v0.21.1-185-gffc5a86098dc01
    machineID: ""
    osImage: Debian GNU/Linux 7 (wheezy)
    systemUUID: ABE5F6B4-D44B-108B-C46A-24CCE16C8B6E
```

### What's next

Learn about additional debugging tools, including:

-   [Logging](https://kubernetes.io/docs/concepts/cluster-administration/logging/)
-   [Monitoring](https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/)
-   [Getting into containers via `exec`](https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/)
-   [Connecting to containers via proxies](https://kubernetes.io/docs/tasks/access-kubernetes-api/http-proxy-access-api/)
-   [Connecting to containers via port forwarding](https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/)
-   [Inspect Kubernetes node with crictl](https://kubernetes.io/docs/tasks/debug-application-cluster/crictl/)











## 监察

**FEATURE STATE:** `Kubernetes v1.15` [feature-state-beta.txt](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/#)

Kubernetes 监察功能提供了与安全相关的按时间顺序排列的记录集，记录单个用户、管理员或系统其他组件影响系统的活动顺序。 它能帮助集群管理员处理以下问题：

-   发生了什么？
-   什么时候发生的？
-   谁触发的？
-   活动发生在哪个（些）对象上？
-   在哪观察到的？
-   它从哪触发的？
-   活动的后续处理行为是什么？

-   [监察策略](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/#%e5%ae%a1%e8%ae%a1%e7%ad%96%e7%95%a5)
-   [监察后端](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/#%e5%ae%a1%e8%ae%a1%e5%90%8e%e7%ab%af)
-   [多集群配置](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/#%e5%a4%9a%e9%9b%86%e7%be%a4%e9%85%8d%e7%bd%ae)
-   [日志选择器示例](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/#%e6%97%a5%e5%bf%97%e9%80%89%e6%8b%a9%e5%99%a8%e7%a4%ba%e4%be%8b)
-   [传统的监察](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/#%e4%bc%a0%e7%bb%9f%e7%9a%84%e5%ae%a1%e8%ae%a1)

[Kube-apiserver](https://kubernetes.io/docs/admin/kube-apiserver) 执行监察。每个执行阶段的每个请求都会生成一个事件，然后根据特定策略对事件进行预处理并写入后端。 您可以在 [设计方案](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/auditing.md) 中找到更多详细信息。 该策略确定记录的内容并且在后端存储记录。当前的后端支持日志文件和 webhook。

每个请求都可以用相关的 “stage” 记录。已知的 stage 有：

-   `RequestReceived` - 事件的 stage 将在监察处理器接收到请求后，并且在委托给其余处理器之前生成。
-   `ResponseStarted` - 在响应消息的头部发送后，但是响应消息体发送前。这个 stage 仅为长时间运行的请求生成（例如 watch）。
-   `ResponseComplete` - 当响应消息体完成并且没有更多数据需要传输的时候。
-   `Panic` - 当 panic 发生时生成。

>   Note:
>
>   **注意** 监察日志记录功能会增加 API server 的内存消耗，因为需要为每个请求存储监察所需的某些上下文。 此外，内存消耗取决于监察日志记录的配置。

### 监察策略

监察政策定义了关于应记录哪些事件以及应包含哪些数据的规则。监察策略对象结构在 [`audit.k8s.io` API 组](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apiserver/pkg/apis/audit/v1beta1/types.go) 中定义。 处理事件时，将按顺序与规则列表进行比较。第一个匹配规则设置事件的 [监察级别][auditing-level]。已知的监察级别有：

-   `None` - 符合这条规则的日志将不会记录。
-   `Metadata` - 记录请求的 metadata（请求的用户、timestamp、resource、verb 等等），但是不记录请求或者响应的消息体。
-   `Request` - 记录事件的 metadata 和请求的消息体，但是不记录响应的消息体。这不适用于非资源类型的请求。
-   `RequestResponse` - 记录事件的 metadata，请求和响应的消息体。这不适用于非资源类型的请求。

您可以使用 `--audit-policy-file` 标志将包含策略的文件传递给 [kube-apiserver](https://kubernetes.io/docs/admin/kube-apiserver)。如果不设置该标志，则不记录事件。 注意 `rules` 字段 **必须** 在监察策略文件中提供。没有（0）规则的策略将被视为非法配置。

以下是一个监察策略文件的示例：

[`audit/audit-policy.yaml`](https://raw.githubusercontent.com/kubernetes/website/master/content/zh/examples/audit/audit-policy.yaml)

```yaml
apiVersion: audit.k8s.io/v1beta1 # This is required.
kind: Policy
# Don't generate audit events for all requests in RequestReceived stage.
omitStages:
  - "RequestReceived"
rules:
  # Log pod changes at RequestResponse level
  - level: RequestResponse
    resources:
    - group: ""
      # Resource "pods" doesn't match requests to any subresource of pods,
      # which is consistent with the RBAC policy.
      resources: ["pods"]
  # Log "pods/log", "pods/status" at Metadata level
  - level: Metadata
    resources:
    - group: ""
      resources: ["pods/log", "pods/status"]

  # Don't log requests to a configmap called "controller-leader"
  - level: None
    resources:
    - group: ""
      resources: ["configmaps"]
      resourceNames: ["controller-leader"]

  # Don't log watch requests by the "system:kube-proxy" on endpoints or services
  - level: None
    users: ["system:kube-proxy"]
    verbs: ["watch"]
    resources:
    - group: "" # core API group
      resources: ["endpoints", "services"]

  # Don't log authenticated requests to certain non-resource URL paths.
  - level: None
    userGroups: ["system:authenticated"]
    nonResourceURLs:
    - "/api*" # Wildcard matching.
    - "/version"

  # Log the request body of configmap changes in kube-system.
  - level: Request
    resources:
    - group: "" # core API group
      resources: ["configmaps"]
    # This rule only applies to resources in the "kube-system" namespace.
    # The empty string "" can be used to select non-namespaced resources.
    namespaces: ["kube-system"]

  # Log configmap and secret changes in all other namespaces at the Metadata level.
  - level: Metadata
    resources:
    - group: "" # core API group
      resources: ["secrets", "configmaps"]

  # Log all other resources in core and extensions at the Request level.
  - level: Request
    resources:
    - group: "" # core API group
    - group: "extensions" # Version of group should NOT be included.

  # A catch-all rule to log all other requests at the Metadata level.
  - level: Metadata
    # Long-running requests like watches that fall under this rule will not
    # generate an audit event in RequestReceived.
    omitStages:
      - "RequestReceived"
```

您可以使用最低限度的监察策略文件在 `Metadata` 级别记录所有请求：

```yaml
# Log all requests at the Metadata level.
apiVersion: audit.k8s.io/v1beta1
kind: Policy
rules:
- level: Metadata
```

管理员构建自己的监察配置文件时，应使用 [GCE 使用的监察配置文件](https://github.com/kubernetes/kubernetes/blob/master/cluster/gce/gci/configure-helper.sh#L735) 作为参考。

### 监察后端

监察后端实现将监察事件导出到外部存储。 [Kube-apiserver](https://kubernetes.io/docs/admin/kube-apiserver) 提供两个后端：

-   Log 后端，将事件写入到磁盘
-   Webhook 后端，将事件发送到外部 API

在这两种情况下，监察事件结构均由 `audit.k8s.io` API 组中的 API 定义。当前版本的 API 是 [`v1beta1`](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apiserver/pkg/apis/audit/v1beta1/types.go)。

>   Note:
>
>   **注意：** 在 patch 请求的情况下，请求的消息体需要是一个 JSON 串指定 patch 操作，而不是一个完整的 Kubernetes API 对象 JSON 串。 例如，以下的示例是一个合法的 patch 请求消息体，该请求对应 `/apis/batch/v1/namespaces/some-namespace/jobs/some-job-name`。
>
>   ```json
>   [
>     {
>       "op": "replace",
>       "path": "/spec/parallelism",
>       "value": 0
>     },
>     {
>       "op": "remove",
>       "path": "/spec/template/spec/containers/0/terminationMessagePolicy"
>     }
>   ]
>   ```

#### Log 后端

Log 后端将监察事件写入 JSON 格式的文件。您可以使用以下 [kube-apiserver](https://kubernetes.io/docs/admin/kube-apiserver) 标志配置 Log 监察后端：

-   `--audit-log-path` 指定用来写入监察事件的日志文件路径。不指定此标志会禁用日志后端。`-` 意味着标准化
-   `--audit-log-maxage` 定义了保留旧监察日志文件的最大天数
-   `--audit-log-maxbackup` 定义了要保留的监察日志文件的最大数量
-   `--audit-log-maxsize` 定义监察日志文件的最大大小（兆字节）

#### Webhook 后端

Webhook 后端将监察事件发送到远程 API，该远程 API 应该暴露与 [kube-apiserver](https://kubernetes.io/docs/admin/kube-apiserver) 相同的API。 您可以使用如下 kube-apiserver 标志来配置 webhook 监察后端：

-   `--audit-webhook-config-file` webhook 配置文件的路径。Webhook 配置文件实际上是一个 [kubeconfig](https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/)。
-   `--audit-webhook-initial-backoff` 指定在第一次失败后重发请求等待的时间。随后的请求将以指数退避重试。

webhook 配置文件使用 kubeconfig 格式指定服务的远程地址和用于连接它的凭据。

#### Batching

log 和 webhook 后端都支持 batch。以 webhook 为例，以下是可用参数列表。要获取 log 后端的同样参数，请在参数名称中将 `webhook` 替换为 `log`。 默认情况下，在 `webhook` 中启用 batch，在 `log` 中禁用 batch。同样，默认情况下，在 `webhook` 中启用限制，在 `log` 中禁用限制。

-   ```
    --audit-webhook-mode
    ```

     

    定义缓存策略，可选值如下：

    -   `batch` - 以批处理缓存事件和异步的过程。这是默认值。
    -   `blocking` - 阻止 API server 处理每个单独事件的响应。

以下参数仅用于 `batch` 模式。

-   `--audit-webhook-batch-buffer-size` 定义 batch 之前要缓存的事件数。 如果传入事件的速率溢出缓存区，则会丢弃事件。
-   `--audit-webhook-batch-max-size` 定义一个 batch 中的最大事件数。
-   `--audit-webhook-batch-max-wait` 无条件 batch 队列中的事件前等待的最大事件。
-   `--audit-webhook-batch-throttle-qps` 每秒生成的最大 batch 平均值。
-   `--audit-webhook-batch-throttle-burst` 在达到允许的 QPS 前，同一时刻允许存在的最大 batch 生成数。

##### 参数调整

需要设置参数以适应 apiserver 上的负载。

例如，如果 kube-apiserver 每秒收到 100 个请求，并且每个请求仅在 `ResponseStarted` 和 `ResponseComplete` 阶段进行监察，则应该考虑每秒生成约 200 个监察事件。 假设批处理中最多有 100 个事件，则应将限制级别设置为至少 2 个 QPS。 假设后端最多需要 5 秒钟来写入事件，您应该设置缓冲区大小以容纳最多 5 秒的事件，即 10 个 batch，即 1000 个事件。

但是，在大多数情况下，默认参数应该足够了，您不必手动设置它们。您可以查看 kube-apiserver 公开的以下 Prometheus 指标，并在日志中监控监察子系统的状态。

-   `apiserver_audit_event_total` 包含所有暴露的监察事件数量的指标。
-   `apiserver_audit_error_total` 在暴露时由于发生错误而被丢弃的事件的数量。

### 多集群配置

如果您通过 [aggregation layer](https://kubernetes.io/docs/concepts/api-extension/apiserver-aggregation) 对 Kubernetes API 进行扩展，那么您也可以为聚合的 apiserver 设置监察日志。 想要这么做，您需要以上述的格式给聚合的 apiserver 配置参数，并且配置日志管道以采用监察日志。不同的 apiserver 可以配置不同的监察配置和策略。

### 日志选择器示例

#### 使用 fluentd 从日志文件中选择并且分发监察日志

[Fluentd](http://www.fluentd.org/) 是一个开源的数据采集器，可以从统一的日志层中采集。 在以下示例中，我们将使用 fluentd 来按照命名空间划分监察事件。

1.  在 kube-apiserver node 节点上安装 [fluentd, fluent-plugin-forest and fluent-plugin-rewrite-tag-filter](http://docs.fluentd.org/v0.12/articles/quickstart#step1-installing-fluentd)

2.  为 fluentd 创建一个配置文件

    ```none
    $ cat <<EOF > /etc/fluentd/config
    # fluentd conf runs in the same host with kube-apiserver
    <source>
        @type tail
        # audit log path of kube-apiserver
        path /var/log/audit
        pos_file /var/log/audit.pos
        format json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%N%z
        tag audit
    </source>
    
    <filter audit>
        #https://github.com/fluent/fluent-plugin-rewrite-tag-filter/issues/13
        type record_transformer
        enable_ruby
        <record>
         namespace ${record["objectRef"].nil? ? "none":(record["objectRef"]["namespace"].nil? ?  "none":record["objectRef"]["namespace"])}
        </record>
    </filter>
    
    <match audit>
        # route audit according to namespace element in context
        @type rewrite_tag_filter
        rewriterule1 namespace ^(.+) ${tag}.$1
    </match>
    
    <filter audit.**>
       @type record_transformer
       remove_keys namespace
    </filter>
    
    <match audit.**>
        @type forest
        subtype file
        remove_prefix audit
        <template>
            time_slice_format %Y%m%d%H
            compress gz
            path /var/log/audit-${tag}.*.log
            format json
            include_time_key true
        </template>
    </match>
    ```

1.  启动 fluentd

    ```shell
    $ fluentd -c /etc/fluentd/config  -vv
    ```

1.  给 kube-apiserver 配置以下参数并启动：

    ```shell
    --audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-log-path=/var/log/kube-audit --audit-log-format=json
    ```

1.  在 `/var/log/audit-*.log` 文件中检查不同命名空间的监察事件

#### 使用 logstash 采集并分发 webhook 后端的监察事件

[Logstash](https://www.elastic.co/products/logstash) 是一个开源的、服务器端的数据处理工具。在下面的示例中，我们将使用 logstash 采集 webhook 后端的监察事件，并且将来自不同用户的事件存入不同的文件。

1.  安装 [logstash](https://www.elastic.co/guide/en/logstash/current/installing-logstash.html)

2.  为 logstash 创建配置文件

    ```none
    $ cat <<EOF > /etc/logstash/config
    input{
        http{
            #TODO, figure out a way to use kubeconfig file to authenticate to logstash
            #https://www.elastic.co/guide/en/logstash/current/plugins-inputs-http.html#plugins-inputs-http-ssl
            port=>8888
        }
    }
    filter{
        split{
            # Webhook audit backend sends several events together with EventList
            # split each event here.
            field=>[items]
            # We only need event subelement, remove others.
            remove_field=>[headers, metadata, apiVersion, "@timestamp", kind, "@version", host]
        }
        mutate{
            rename => {items=>event}
        }
    }
    output{
        file{
            # Audit events from different users will be saved into different files.
            path=>"/var/log/kube-audit-%{[event][user][username]}/audit"
        }
    }
    ```

1.  启动 logstash

    ```shell
    $ bin/logstash -f /etc/logstash/config --path.settings /etc/logstash/
    ```

1.  为 kube-apiserver webhook 监察后端创建一个 [kubeconfig 文件](https://kubernetes.io/docs/tasks/access-application-cluster/authenticate-across-clusters-kubeconfig/)

    \```none $ cat < /etc/kubernetes/audit-webhook-kubeconfig apiVersion: v1 clusters:

    -   cluster: server: http://:8888 name: logstash contexts:
    -   context: cluster: logstash user: “” name: default-context current-context: default-context kind: Config preferences: {} users: [] EOF ```

1.  为 kube-apiserver 配置以下参数并启动：

    ```shell
    --audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-webhook-config-file=/etc/kubernetes/audit-webhook-kubeconfig
    ```

1.  在 logstash node 节点的 `/var/log/kube-audit-*/audit` 目录中检查监察事件

注意到，除了文件输出插件外，logstash 还有其它多种输出可以让用户路由不同的数据。例如，用户可以将监察事件发送给支持全文搜索和分析的 elasticsearch 插件。

### 传统的监察

**注意：** 传统监察已被弃用，自 1.8 版本以后默认禁用，并且将会在 1.12 版本中彻底移除。 如果想要回退到传统的监察功能，请使用 [kube-apiserver](https://kubernetes.io/docs/admin/kube-apiserver) 中 feature gate 的 `AdvancedAuditing`功能来禁用高级审核功能：

```
--feature-gates=AdvancedAuditing=false
```

在传统格式中，每个监察文件条目包含两行：

1.  请求行包含唯一 ID 以匹配响应和请求元数据，例如源 IP、请求用户、模拟信息和请求的资源等。
2.  响应行包含与请求行和响应代码相匹配的唯一 ID。

```
2017-03-21T03:57:09.106841886-04:00 AUDIT: id="c939d2a7-1c37-4ef1-b2f7-4ba9b1e43b53" ip="127.0.0.1" method="GET" user="admin" groups="\"system:masters\",\"system:authenticated\"" as="<self>" asgroups="<lookup>" namespace="default" uri="/api/v1/namespaces/default/pods"
2017-03-21T03:57:09.108403639-04:00 AUDIT: id="c939d2a7-1c37-4ef1-b2f7-4ba9b1e43b53" response="200"
```

#### 配置

[Kube-apiserver](https://kubernetes.io/docs/admin/kube-apiserver) 提供以下选项，负责配置审核日志的位置和处理方式：

-   `audit-log-path` - 使监察日志指向请求被记录到的文件，’-’ 表示标准输出。
-   `audit-log-maxage` - 根据文件名中编码的时间戳指定保留旧监察日志文件的最大天数。
-   `audit-log-maxbackup` - 指定要保留的旧监察日志文件的最大数量。
-   `audit-log-maxsize` - 指定审核日志文件的最大大小（兆字节）。默认为100MB。

如果审核日志文件已经存在，则 Kubernetes 会将新的审核日志附加到该文件。 否则，Kubernetes 会在您在 `audit-log-path` 中指定的位置创建一个监察日志文件。 如果监察日志文件超过了您在 `audit-log-maxsize` 中指定的大小，则 Kubernetes 将通过在文件名（在文件扩展名之前）附加当前时间戳并重新创建一个新的监察日志文件来重命名当前日志文件。 Kubernetes 可能会在创建新的日志文件时删除旧的日志文件; 您可以通过指定 `audit-log-maxbackup` 和 `audit-log-maxage` 选项来配置保留多少文件以及它们的保留时间。





## 调试Init容器

此页显示如何核查与 init 容器执行相关的问题。 下面的示例命令行将 Pod 称为 `<pod-name>`，而 init 容器称为 `<init-container-1>` 和 `<init-container-2>`。

### 准备开始

你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。 如果你还没有集群，你可以通过 [Minikube](https://v1-14.docs.kubernetes.io/docs/getting-started-guides/minikube) 构建一 个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：

-   [Katacoda](https://www.katacoda.com/courses/kubernetes/playground)
-   [Play with Kubernetes](http://labs.play-with-k8s.com/) –>

To check the version, enter `kubectl version`.

-   您应该熟悉 [Init 容器](https://v1-14.docs.kubernetes.io/docs/concepts/abstractions/init-containers/)的基础知识。
-   您应该已经[配置好一个 Init 容器](https://v1-14.docs.kubernetes.io/docs/tasks/configure-pod-container/configure-pod-initialization/#creating-a-pod-that-has-an-init-container/)。

### 检查 Init 容器的状态

显示你的 Pod 的状态：

```shell
kubectl get pod <pod-name>
```

例如，状态 `Init:1/2` 表明两个 Init 容器中的一个已经成功完成：

```
NAME         READY     STATUS     RESTARTS   AGE
<pod-name>   0/1       Init:1/2   0          7s
```

更多状态值及其含义请参考[了解 Pod 的状态](https://v1-14.docs.kubernetes.io/zh/docs/tasks/debug-application-cluster/debug-init-containers/#understanding-pod-status)。

### 获取 Init 容器详情

查看 Init 容器运行的更多详情：

```shell
kubectl describe pod <pod-name>
```

例如，对于包含两个 Init 容器的 Pod 应该显示如下信息：

```
Init Containers:
  <init-container-1>:
    Container ID:    ...
    ...
    State:           Terminated
      Reason:        Completed
      Exit Code:     0
      Started:       ...
      Finished:      ...
    Ready:           True
    Restart Count:   0
    ...
  <init-container-2>:
    Container ID:    ...
    ...
    State:           Waiting
      Reason:        CrashLoopBackOff
    Last State:      Terminated
      Reason:        Error
      Exit Code:     1
      Started:       ...
      Finished:      ...
    Ready:           False
    Restart Count:   3
    ...
```

您还可以通过读取 Pod Spec 上的 `status.initContainerStatuses` 字段以编程方式了解 Init 容器的状态：

```shell
kubectl get pod nginx --template '{{.status.initContainerStatuses}}'
```

此命令将返回与原始 JSON 中相同的信息.

### 通过 Init 容器访问日志

一起传递 Init 容器名称与 Pod 名称来访问它的日志。

```shell
kubectl logs <pod-name> -c <init-container-2>
```

运行 shell 脚本打印命令的init容器,执行 shell 脚本。 例如，您可以在 Bash 中通过在脚本的开头运行 `set -x` 来实现。

### 了解 Pod 的状态

以 `Init:` 开头的 Pod 状态汇总了 Init 容器执行的状态。 下表介绍调试 Init 容器时可能看到的一些状态值示例。

| 状态                           | 含义                                                 |
| :----------------------------- | :--------------------------------------------------- |
| `Init:N/M`                     | Pod 包含 `M` 个 Init 容器，其中 `N` 个已经运行完成。 |
| `Init:Error`                   | Init 容器已执行失败。                                |
| `Init:CrashLoopBackOff`        | Init 容器反复执行失败。                              |
| `Pending`                      | Pod 还没有开始执行 Init 容器。                       |
| `PodInitializing` or `Running` | Pod 已经完成执行 Init 容器。                         |





## 调试pod和复制控制器

### 调试Pods

调试一个pod的第一步是观察它。使用下面的命令检查这个pod的当前状态和最近事件：

```
$ kubectl describe pods ${POD_NAME}
```

看看pod中的容器的状态。他们都是`Running`吗？有最近重启了吗？

根据pod的状态继续调试。

#### 我的Pod保持Pending

如果一个pod被卡在`Pending`中，就意味着它不能调度在某个节点上。一般来说，这是因为某种类型的资源不足 阻止调度。 看看上面的命令`kubectl describe ...`的输出。调度器的消息中应该会包含无法调度Pod的原因。 理由包括：

##### 资源不足

您可能已经耗尽了集群中供应的CPU或内存。在这个情况下你可以尝试几件事情：

-   [添加更多节点](https://kubernetes.io/docs/admin/cluster-management/#resizing-a-cluster) 到集群。

-   [终止不需要的pod](https://kubernetes.io/docs/user-guide/pods/single-container/#deleting_a_pod) 为pending中的pods提供空间。

-   检查该pod是否不大于您的节点。例如，如果全部节点具有`cpu:1`容量，那么具有`cpu: 1.1`请求的pod永远不会被调度。

    您可以使用`kubectl get nodes -o <format>`命令来检查节点容量。 下面是一些能够提取必要信息的命令示例：

    kubectl get nodes -o yaml | grep ‘\sname|cpu|memory’ kubectl get nodes -o json | jq ‘.items[] | {name: .metadata.name, cap: .status.capacity}’

可以考虑配置[资源配额](https://kubernetes.io/docs/concepts/policy/resource-quotas/)来限制可耗用的资源总量。如果与命名空间一起使用，它可以防止一个团队吞噬所有的资源。

##### 使用hostPort

当你将一个pod绑定到一个`hostPort`时，这个pod能被调度的位置数量有限。 在大多数情况下，`hostPort`是不必要的; 尝试使用服务对象来暴露您的pod。 如果你需要`hostPort`，那么你可以调度的Pod数量不能超过集群的节点个数。

#### 我的Pod一直在Waiting

如果一个pod被卡在`Waiting`状态，那么它已被调度在某个工作节点，但它不能在该机器上运行。 再次，来自`kubectl describe ...`的内容应该是可以提供信息的。 最常见的原因`Waiting`的pod是无法拉取镜像。有三件事要检查：

-   确保您的镜像的名称正确。
-   您是否将镜像推送到存储库？
-   在您的机器上手动运行`docker pull <image>`，看看是否可以拉取镜像。

#### 我的Pod一直Crashing或者有别的不健康状态

首先，查看当前容器的日志：

```
$ kubectl logs ${POD_NAME} ${CONTAINER_NAME}
```

如果您的容器先前已崩溃，则可以访问上一个容器的崩溃日志：

```
$ kubectl logs --previous ${POD_NAME} ${CONTAINER_NAME}
```

或者，您可以使用`exec`在该容器内运行命令：

```
$ kubectl exec ${POD_NAME} -c ${CONTAINER_NAME} -- ${CMD} ${ARG1} ${ARG2} ... ${ARGN}
```

请注意，`-c ${CONTAINER_NAME}`是可选的，对于pod只包含一个容器可以省略。

例如，要查看正在运行的Cassandra pod的日志，可以运行：

```
$ kubectl exec cassandra -- cat /var/log/cassandra/system.log
```

如果这些方法都不起作用，您可以找到该运行pod所在的主机并SSH到该主机。

### 调试Replication Controllers

Replication Controllers相当简单。他们能或不能创建pod。如果他们无法创建pod，那么请参考 [上面的说明](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/debug-pod-replication-controller/#debugging_pods)来调试你的pod。

您也可以使用`kubectl describe rc ${CONTROLLER_NAME}`来检查和Replication Controllers有关的事件。







## 调试服务

对于新安装的 Kubernetes，经常出现的一个问题是 `Service` 没有正常工作。如果您已经运行了 `Deployment` 并创建了一个 `Service`，但是当您尝试访问它时没有得到响应，希望这份文档能帮助您找出问题所在。

### 约定

在整个文档中，您将看到各种可以运行的命令。有些命令需要在 `Pod` 中运行，有些命令需要在 Kubernetes `Node` 上运行，还有一些命令可以在您拥有 `kubectl` 和集群凭证的任何地方运行。为了明确预期的效果，本文档将使用以下约定。

如果命令 “COMMAND” 期望在 `Pod` 中运行，并且产生 “OUTPUT”：

```shell
u@pod$ COMMAND
OUTPUT
```

如果命令 “COMMAND” 期望在 `Node` 上运行，并且产生 “OUTPUT”：

```shell
u@node$ COMMAND
OUTPUT
```

如果命令是 “kubectl ARGS”：

```shell
$ kubectl ARGS
OUTPUT
```

### 在 pod 中运行命令

对于这里的许多步骤，您可能希望知道运行在集群中的 `Pod` 看起来是什么样的。最简单的方法是运行一个交互式的 busybox `Pod`：

```none
$ kubectl run -it --rm --restart=Never busybox --image=busybox sh
如果你没有看到命令提示符，请尝试按 Enter 键。
/ #
```

如果您已经有了您喜欢使用的正在运行的 `Pod`，则可以运行一下命令去使用：

```shell
$ kubectl exec <POD-NAME> -c <CONTAINER-NAME> -- <COMMAND>
```

### 设置

为了完成本次演练的目的，我们先运行几个 `Pod`。因为可能正在调试您自己的 `Service`，所以，您可以使用自己的详细信息进行替换，或者，您也可以跟随并开始下面的步骤来获得第二个数据点。

```shell
$ kubectl run hostnames --image=k8s.gcr.io/serve_hostname \
                        --labels=app=hostnames \
                        --port=9376 \
                        --replicas=3
deployment.apps/hostnames created
```

`kubectl` 命令将打印创建或变更的资源的类型和名称，它们可以在后续命令中使用。

>   Note:
>
>   这与您使用以下 YAML 启动 `Deployment` 相同：
>
>   ```yaml
>   apiVersion: apps/v1
>   kind: Deployment
>   metadata:
>     name: hostnames
>   spec:
>     selector:
>       matchLabels:
>         app: hostnames
>     replicas: 3
>     template:
>       metadata:
>         labels:
>           app: hostnames
>       spec:
>         containers:
>         - name: hostnames
>           image: k8s.gcr.io/serve_hostname
>           ports:
>           - containerPort: 9376
>             protocol: TCP
>   ```



确认您的 `Pods` 是运行状态:

```shell
$ kubectl get pods -l app=hostnames
NAME                        READY     STATUS    RESTARTS   AGE
hostnames-632524106-bbpiw   1/1       Running   0          2m
hostnames-632524106-ly40y   1/1       Running   0          2m
hostnames-632524106-tlaok   1/1       Running   0          2m
```

### Service 存在吗？

细心的读者会注意到我们还没有真正创建一个 `Service` - 其实这是我们有意的。这是一个有时会被遗忘的步骤，也是第一件要检查的事情。

那么，如果我试图访问一个不存在的 `Service`，会发生什么呢？假设您有另一个 `Pod`，想通过名称使用这个 `Service`，您将得到如下内容：

```shell
u@pod$ wget -O- hostnames
Resolving hostnames (hostnames)... failed: Name or service not known.
wget: unable to resolve host address 'hostnames'
```

因此，首先要检查的是 `Service` 是否确实存在：

```shell
$ kubectl get svc hostnames
No resources found.
Error from server (NotFound): services "hostnames" not found
```

我们已经有一个罪魁祸首了，让我们来创建 `Service`。就像前面一样，这里的内容仅仅是为了步骤的执行 - 在这里您可以使用自己的 `Service` 细节。

```shell
$ kubectl expose deployment hostnames --port=80 --target-port=9376
service/hostnames exposed
```

再查询一遍，确定一下：

```shell
$ kubectl get svc hostnames
NAME        TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
hostnames   ClusterIP   10.0.1.175   <none>        80/TCP    5s
```

与前面相同，这与您使用 YAML 启动的 `Service` 一样：

```yaml
apiVersion: v1
kind: Service
metadata:
  name: hostnames
spec:
  selector:
    app: hostnames
  ports:
  - name: default
    protocol: TCP
    port: 80
    targetPort: 9376
```

现在您可以确认 `Service` 存在。

### Service 是否通过 DNS 工作？

从相同 `Namespace` 下的 `Pod` 中运行：

```shell
u@pod$ nslookup hostnames
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      hostnames
Address 1: 10.0.1.175 hostnames.default.svc.cluster.local
```

如果失败，那么您的 `Pod` 和 `Service` 可能位于不同的 `Namespace` 中，请尝试使用限定命名空间的名称：

```shell
u@pod$ nslookup hostnames.default
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      hostnames.default
Address 1: 10.0.1.175 hostnames.default.svc.cluster.local
```

如果成功，那么需要调整您的应用，使用跨命名空间的名称去访问服务，或者，在相同的 `Namespace` 中运行应用和 `Service`。如果仍然失败，请尝试一个完全限定的名称：

```shell
u@pod$ nslookup hostnames.default.svc.cluster.local
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      hostnames.default.svc.cluster.local
Address 1: 10.0.1.175 hostnames.default.svc.cluster.local
```

注意这里的后缀：”default.svc.cluster.local”。”default” 是我们正在操作的 `Namespace`。”svc” 表示这是一个 `Service`。”cluster.local” 是您的集群域，在您自己的集群中可能会有所不同。

您也可以在集群中的 Node 上尝试此操作：

>   **Note:** 10.0.0.10 是我的 DNS `Service`，您的可能不同）.

```shell
u@node$ nslookup hostnames.default.svc.cluster.local 10.0.0.10
Server:         10.0.0.10
Address:        10.0.0.10#53

Name:   hostnames.default.svc.cluster.local
Address: 10.0.1.175
```

如果您能够使用完全限定的名称查找，但不能使用相对名称，则需要检查 `/etc/resolv.conf` 文件是否正确。

```shell
u@pod$ cat /etc/resolv.conf
nameserver 10.0.0.10
search default.svc.cluster.local svc.cluster.local cluster.local example.com
options ndots:5
```

`nameserver` 行必须指示您的集群的 DNS `Service`，它通过 `--cluster-dns` 标志传递到 `kubelet`。

`search` 行必须包含一个适当的后缀，以便查找 `Service` 名称。在本例中，它在本地 `Namespace`（`default.svc.cluster.local`）、所有 `Namespace` 中的 `Service`（`svc.cluster.local`）以及集群（`cluster.local`）中查找服务。 根据您自己的安装情况，可能会有额外的记录（最多 6 条）。集群后缀通过 `--cluster-domain` 标志传递给 `kubelet`。 本文档中，我们假定它是 “cluster.local”，但是您的可能不同，这种情况下，您应该在上面的所有命令中更改它。

`options` 行必须设置足够高的 `ndots`，以便 DNS 客户端库考虑搜索路径。在默认情况下，Kubernetes 将这个值设置为 5，这个值足够高，足以覆盖它生成的所有 DNS 名称。

#### DNS 中是否存在任何服务？

如果上面仍然失败 - DNS 查找不到您需要的 `Service` - 我们可以后退一步，看看还有什么不起作用。Kubernetes 主 `Service` 应该一直是工作的：

```shell
u@pod$ nslookup kubernetes.default
Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes.default
Address 1: 10.0.0.1 kubernetes.default.svc.cluster.local
```

如果失败，您可能需要转到这个文档的 kube-proxy 部分，或者甚至回到文档的顶部重新开始，但不是调试您自己的 `Service`，而是调试 DNS。

#### Service 能够通过 IP 访问么？

假设我们可以确认 DNS 工作正常，那么接下来要测试的是您的 `Service` 是否工作正常。从集群中的一个节点，访问 `Service` 的 IP（从上面的 `kubectl get` 命令获取）。

```shell
u@node$ curl 10.0.1.175:80
hostnames-0uton

u@node$ curl 10.0.1.175:80
hostnames-yp2kp

u@node$ curl 10.0.1.175:80
hostnames-bvc05
```

如果 `Service` 是正常的，您应该得到正确的响应。如果没有，有很多可能出错的地方，请继续。

### Service 是对的吗？

这听起来可能很愚蠢，但您应该加倍甚至三倍检查您的 `Service` 是否正确，并且与您的 `Pod`匹配。查看您的 `Service` 并验证它：

```shell
$ kubectl get service hostnames -o json
{
    "kind": "Service",
    "apiVersion": "v1",
    "metadata": {
        "name": "hostnames",
        "namespace": "default",
        "selfLink": "/api/v1/namespaces/default/services/hostnames",
        "uid": "428c8b6c-24bc-11e5-936d-42010af0a9bc",
        "resourceVersion": "347189",
        "creationTimestamp": "2015-07-07T15:24:29Z",
        "labels": {
            "app": "hostnames"
        }
    },
    "spec": {
        "ports": [
            {
                "name": "default",
                "protocol": "TCP",
                "port": 80,
                "targetPort": 9376,
                "nodePort": 0
            }
        ],
        "selector": {
            "app": "hostnames"
        },
        "clusterIP": "10.0.1.175",
        "type": "ClusterIP",
        "sessionAffinity": "None"
    },
    "status": {
        "loadBalancer": {}
    }
}
```

`spec.ports[]` 中描述的是您想要尝试访问的端口吗？`targetPort` 对您的 `Pod` 来说正确吗（许多 `Pod` 选择使用与 `Service` 不同的端口）？如果您想把它变成一个数字端口，那么它是一个数字（9376）还是字符串 “9376”？如果您想把它当作一个指定的端口，那么您的 `Pod`是否公开了一个同名端口？端口的 `protocol` 和 `Pod` 的一样吗？

### Service 有端点吗？

如果您已经走到了这一步，我们假设您已经确认您的 `Service` 存在，并能通过 DNS 解析。现在，让我们检查一下，您运行的 `Pod` 确实是由 `Service` 选择的。

早些时候，我们已经看到 `Pod` 是运行状态。我们可以再检查一下：

```shell
$ kubectl get pods -l app=hostnames
NAME              READY     STATUS    RESTARTS   AGE
hostnames-0uton   1/1       Running   0          1h
hostnames-bvc05   1/1       Running   0          1h
hostnames-yp2kp   1/1       Running   0          1h
```

“AGE” 列表明这些 `Pod` 已经启动一个小时了，这意味着它们运行良好，而不是崩溃。

`-l app=hostnames` 参数是一个标签选择器 - 就像我们的 `Service` 一样。在 Kubernetes 系统中有一个控制循环，它评估每个 `Service` 的选择器，并将结果保存到 `Endpoints` 对象中。

```shell
$ kubectl get endpoints hostnames
NAME        ENDPOINTS
hostnames   10.244.0.5:9376,10.244.0.6:9376,10.244.0.7:9376
```

这证实 endpoints 控制器已经为您的 `Service` 找到了正确的 `Pods`。如果 `hostnames` 行为空，则应检查 `Service` 的 `spec.selector` 字段，以及您实际想选择的 `Pods` 的 `metadata.labels` 的值。常见的错误是输入错误或其他错误，例如 `Service` 想选择 `run=hostnames`，但是 `Deployment` 指定的是 `app=hostnames`。

### Pod 正常工作吗？

到了这步，我们知道您的 `Service` 存在并选择了您的 `Pods`。让我们检查一下 `Pod` 是否真的在工作 - 我们可以绕过 `Service` 机制，直接进入 `Pod`。

>   **Note:** 这些命令使用的是 `Pod` 端口（9376），而不是 `Service` 端口（80）。

```shell
u@pod$ wget -qO- 10.244.0.5:9376
hostnames-0uton

pod $ wget -qO- 10.244.0.6:9376
hostnames-bvc05

u@pod$ wget -qO- 10.244.0.7:9376
hostnames-yp2kp
```

我们期望的是 `Endpoints` 列表中的每个 `Pod` 返回自己的主机名。如果这没有发生（或者您自己的 `Pod` 的正确行为没有发生），您应该调查发生了什么。您会发现 `kubectl logs` 这个时候非常有用，或者使用 `kubectl exec` 直接进入到您的 `Pod`，并从那里检查服务。

另一件要检查的事情是，您的 Pod 没有崩溃或正在重新启动。频繁的重新启动可能会导致断断续续的连接问题。

```shell
$ kubectl get pods -l app=hostnames
NAME                        READY     STATUS    RESTARTS   AGE
hostnames-632524106-bbpiw   1/1       Running   0          2m
hostnames-632524106-ly40y   1/1       Running   0          2m
hostnames-632524106-tlaok   1/1       Running   0          2m
```

如果重新启动计数很高，请查阅有关如何[调试 pods](https://v1-14.docs.kubernetes.io/docs/tasks/debug-application-cluster/debug-pod-replication-controller/#debugging-pods) 获取更多信息。

### kube-proxy 正常工作吗？

如果您到了这里，那么您的 `Service` 正在运行，也有 `Endpoints`，而您的 `Pod` 实际上也正在服务。在这一点上，整个 `Service` 代理机制是否正常就是可疑的了。我们来确认一下，一部分一部分来。

#### kube-proxy 在运行吗？

确认 `kube-proxy` 正在您的 `Nodes` 上运行。您应该得到如下内容：

```shell
u@node$ ps auxw | grep kube-proxy
root  4194  0.4  0.1 101864 17696 ?    Sl Jul04  25:43 /usr/local/bin/kube-proxy --master=https://kubernetes-master --kubeconfig=/var/lib/kube-proxy/kubeconfig --v=2
```

下一步，确认它并没有出现明显的失败，比如连接主节点失败。要做到这一点，您必须查看日志。访问日志取决于您的 `Node` 操作系统。在某些操作系统是一个文件，如 /var/log/messages kube-proxy.log，而其他操作系统使用 `journalctl` 访问日志。您应该看到类似的东西：

```none
I1027 22:14:53.995134    5063 server.go:200] Running in resource-only container "/kube-proxy"
I1027 22:14:53.998163    5063 server.go:247] Using iptables Proxier.
I1027 22:14:53.999055    5063 server.go:255] Tearing down userspace rules. Errors here are acceptable.
I1027 22:14:54.038140    5063 proxier.go:352] Setting endpoints for "kube-system/kube-dns:dns-tcp" to [10.244.1.3:53]
I1027 22:14:54.038164    5063 proxier.go:352] Setting endpoints for "kube-system/kube-dns:dns" to [10.244.1.3:53]
I1027 22:14:54.038209    5063 proxier.go:352] Setting endpoints for "default/kubernetes:https" to [10.240.0.2:443]
I1027 22:14:54.038238    5063 proxier.go:429] Not syncing iptables until Services and Endpoints have been received from master
I1027 22:14:54.040048    5063 proxier.go:294] Adding new service "default/kubernetes:https" at 10.0.0.1:443/TCP
I1027 22:14:54.040154    5063 proxier.go:294] Adding new service "kube-system/kube-dns:dns" at 10.0.0.10:53/UDP
I1027 22:14:54.040223    5063 proxier.go:294] Adding new service "kube-system/kube-dns:dns-tcp" at 10.0.0.10:53/TCP
```

如果您看到有关无法连接主节点的错误消息，则应再次检查节点配置和安装步骤。

`kube-proxy` 无法正确运行的可能原因之一是找不到所需的 `conntrack` 二进制文件。在一些 Linux 系统上，这也是可能发生的，这取决于您如何安装集群，例如，您正在从头开始安装 Kubernetes。如果是这样的话，您需要手动安装 `conntrack` 包（例如，在 Ubuntu 上使用 `sudo apt install conntrack`），然后重试。

#### kube-proxy 是否在写 iptables 规则？

`kube-proxy` 的主要职责之一是写实现 `Services` 的 `iptables` 规则。让我们检查一下这些规则是否已经被写好了。

kube-proxy 可以在 “userspace” 模式、 “iptables” 模式或者 “ipvs” 模式下运行。 希望您正在使用 “iptables” 模式或者 “ipvs” 模式。您应该看到以下情况之一。

##### Userpace

```shell
u@node$ iptables-save | grep hostnames
-A KUBE-PORTALS-CONTAINER -d 10.0.1.175/32 -p tcp -m comment --comment "default/hostnames:default" -m tcp --dport 80 -j REDIRECT --to-ports 48577
-A KUBE-PORTALS-HOST -d 10.0.1.175/32 -p tcp -m comment --comment "default/hostnames:default" -m tcp --dport 80 -j DNAT --to-destination 10.240.115.247:48577
```

您的 `Service` 上的每个端口应该有两个规则（本例中只有一个）- “KUBE-PORTALS-CONTAINER” 和 “KUBE-PORTALS-HOST”。如果您没有看到这些，请尝试将 `-V` 标志设置为 4 之后重新启动 `kube-proxy`，然后再次查看日志。

几乎没有人应该再使用 “userspace” 模式了，所以我们不会在这里花费更多的时间。

##### Iptables

```shell
u@node$ iptables-save | grep hostnames
-A KUBE-SEP-57KPRZ3JQVENLNBR -s 10.244.3.6/32 -m comment --comment "default/hostnames:" -j MARK --set-xmark 0x00004000/0x00004000
-A KUBE-SEP-57KPRZ3JQVENLNBR -p tcp -m comment --comment "default/hostnames:" -m tcp -j DNAT --to-destination 10.244.3.6:9376
-A KUBE-SEP-WNBA2IHDGP2BOBGZ -s 10.244.1.7/32 -m comment --comment "default/hostnames:" -j MARK --set-xmark 0x00004000/0x00004000
-A KUBE-SEP-WNBA2IHDGP2BOBGZ -p tcp -m comment --comment "default/hostnames:" -m tcp -j DNAT --to-destination 10.244.1.7:9376
-A KUBE-SEP-X3P2623AGDH6CDF3 -s 10.244.2.3/32 -m comment --comment "default/hostnames:" -j MARK --set-xmark 0x00004000/0x00004000
-A KUBE-SEP-X3P2623AGDH6CDF3 -p tcp -m comment --comment "default/hostnames:" -m tcp -j DNAT --to-destination 10.244.2.3:9376
-A KUBE-SERVICES -d 10.0.1.175/32 -p tcp -m comment --comment "default/hostnames: cluster IP" -m tcp --dport 80 -j KUBE-SVC-NWV5X2332I4OT4T3
-A KUBE-SVC-NWV5X2332I4OT4T3 -m comment --comment "default/hostnames:" -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-WNBA2IHDGP2BOBGZ
-A KUBE-SVC-NWV5X2332I4OT4T3 -m comment --comment "default/hostnames:" -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-X3P2623AGDH6CDF3
-A KUBE-SVC-NWV5X2332I4OT4T3 -m comment --comment "default/hostnames:" -j KUBE-SEP-57KPRZ3JQVENLNBR
```

`KUBE-SERVICES` 中应该有 1 条规则，`KUBE-SVC-(hash)` 中每个端点有 1 或 2 条规则（取决于 `SessionAffinity`），每个端点中应有 1 条 `KUBE-SEP-(hash)` 链。准确的规则将根据您的确切配置（包括节点、端口组合以及负载均衡器设置）而有所不同。

##### IPVS

```shell
u@node$ ipvsadm -ln
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
...
TCP  10.0.1.175:80 rr
  -> 10.244.0.5:9376               Masq    1      0          0
  -> 10.244.0.6:9376               Masq    1      0          0
  -> 10.244.0.7:9376               Masq    1      0          0
...
```

IPVS 代理将为每个服务器地址（例如集群 IP、外部 IP、节点端口 IP、负载均衡 IP等）创建虚拟服务器，并为服务的端点创建一些相应的真实服务器（如果有）。在这个例子中，服务器主机名（`10.0.1.175:80`）有 3 个端点(`10.244.0.5:9376`, `10.244.0.6:9376`, `10.244.0.7:9376`)，你会得到类似上面的结果。

#### kube-proxy 在执行代理操作么？

假设您确实看到了上述规则，请再次尝试通过 IP 访问您的 `Service`：

```shell
u@node$ curl 10.0.1.175:80
hostnames-0uton
```

如果失败了，并且您正在使用 userspace 代理，您可以尝试直接访问代理。如果您使用的是 iptables 代理，请跳过本节。

回顾上面的 `iptables-save` 输出，并提取 `kube-proxy` 用于您的 `Service` 的端口号。在上面的例子中，它是 “48577”。现在连接到它：

```shell
u@node$ curl localhost:48577
hostnames-yp2kp
```

如果仍然失败，请查看 `kube-proxy` 日志中的特定行，如：

```shell
Setting endpoints for default/hostnames:default to [10.244.0.5:9376 10.244.0.6:9376 10.244.0.7:9376]
```

如果您没有看到这些，请尝试将 `-V` 标志设置为 4 并重新启动 `kube-proxy`，然后再查看日志。

#### Pod 无法通过 Service IP 访问自己

如果网络没有为“发夹模式”流量生成正确配置，通常当 `kube-proxy` 以 `iptables` 模式运行，并且 Pod 与桥接网络连接时，就会发生这种情况。`Kubelet` 公开了一个 `hairpin-mode`标志，如果 pod 试图访问它们自己的 Service VIP，就可以让 Service 的端点重新负载到他们自己身上。`hairpin-mode` 标志必须设置为 `hairpin-veth` 或者 `promiscuous-bridge`。

解决这一问题的常见步骤如下：

-   确认 `hairpin-mode` 被设置为 `hairpin-veth` 或者 `promiscuous-bridge`。您应该看到下面这样的内容。在下面的示例中，`hairpin-mode` 被设置为 `promiscuous-bridge`。

```shell
u@node$ ps auxw|grep kubelet
root      3392  1.1  0.8 186804 65208 ?        Sl   00:51  11:11 /usr/local/bin/kubelet --enable-debugging-handlers=true --config=/etc/kubernetes/manifests --allow-privileged=True --v=4 --cluster-dns=10.0.0.10 --cluster-domain=cluster.local --configure-cbr0=true --cgroup-root=/ --system-cgroups=/system --hairpin-mode=promiscuous-bridge --runtime-cgroups=/docker-daemon --kubelet-cgroups=/kubelet --babysit-daemons=true --max-pods=110 --serialize-image-pulls=false --outofdisk-transition-frequency=0
```

-   确认有效的 `hairpin-mode`。要做到这一点，您必须查看 kubelet 日志。访问日志取决于节点的操作系统。在一些操作系统上，它是一个文件，如 /var/log/kubelet.log，而其他操作系统则使用 `journalctl` 访问日志。请注意，由于兼容性，有效的 `hairpin-mode` 可能不匹配 `--hairpin-mode` 标志。在 kubelet.log 中检查是否有带有关键字 `hairpin` 的日志行。应该有日志行指示有效的 `hairpin-mode`，比如下面的内容。

    ```shell
    I0629 00:51:43.648698    3252 kubelet.go:380] Hairpin mode set to "promiscuous-bridge"
    ```

-   如果有效的发夹模式是 `hairpin-veth`，请确保 `Kubelet` 具有在节点上的 `/sys` 中操作的权限。如果一切正常工作，您应该看到如下内容：

```shell
for intf in /sys/devices/virtual/net/cbr0/brif/*; do cat $intf/hairpin_mode; done
1
1
1
1
```

-   如果有效的发夹模式是 `promiscuous-bridge`，则请确保 `Kubelet` 拥有在节点上操纵 Linux 网桥的权限。如果正确使用和配置了 cbr0 网桥，您应该看到：

```shell
u@node$ ifconfig cbr0 |grep PROMISC
UP BROADCAST RUNNING PROMISC MULTICAST  MTU:1460  Metric:1
```

-   如果上述任何一项都没有效果，请寻求帮助。

### 寻求帮助

如果您走到这一步，那么就真的是奇怪的事情发生了。您的 `Service` 正在运行，有 `Endpoints`，您的 `Pods` 也确实在服务中。您的 DNS 正常，`iptables` 规则已经安装，`kube-proxy` 看起来也正常。然而 `Service` 不起作用。这种情况下，您应该让我们知道，这样我们可以帮助调查！

使用 [Slack](https://v1-14.docs.kubernetes.io/docs/troubleshooting/#slack) 或者 [Forum](https://discuss.kubernetes.io/) 或者 [GitHub](https://github.com/kubernetes/kubernetes) 联系我们。





## 调试状态集（StatefulSet）

此任务展示如何调试StatefulSet。

### 准备工作

-   你需要有一个Kubernetes集群，通过必要的配置使kubectl命令行工具与您的集群进行通信。
-   你应该有一个运行中的StatefulSet，以便用于调试。

### 调试StatefulSet

由于StatefulSet在创建时设置了`app=myapp`标签，列出仅属于该StatefulSet的所有pod时，可以使用以下命令：

```shell
kubectl get pods -l app=myapp
```

如果您发现列出的任何Pods长时间处于`Unknown` 或`Terminating`状态，关于如何处理它们的说明任务,请参阅[删除 StatefulSet Pods](https://kubernetes.io/docs/tasks/manage-stateful-set/delete-pods/)。您可以参考[调试 Pods](https://kubernetes.io/docs/user-guide/debugging-pods-and-replication-controllers/#debugging-pods)指南来调试StatefulSet中的各个Pod。

StatefulSets提供调试机制，可以使用注解来暂停所有控制器在Pod上的操作。在任何StatefulSet Pod上设置`pod.alpha.kubernetes.io/initialized`注解为`"false"`将*暂停*StatefulSet的所有操作。暂停时，StatefulSet将不执行任何伸缩操作。一旦调试钩子设置完成后，就可以在StatefulSet pod的容器内执行命令，而不会造成伸缩操作的干扰。您可以通过执行以下命令将注解设置为`"false"`：

```shell
kubectl annotate pods <pod-name> pod.alpha.kubernetes.io/initialized="false" --overwrite
```

当注解设置为`"false"`时，StatefulSet在其Pods变得不健康或不可用时将不会响应。StatefulSet不会创建副本Pod直到每个Pod上删除注解或将注解设置为`"true"`。

#### 逐步初始化

创建StatefulSet之前，您可以通过使用和上文相同的注解，即将yaml文件中`.spec.template.metadata.annotations`里的`pod.alpha.kubernetes.io/initialized`字段设置为`"false"`，对竞态条件的StatefulSet进行调试。

```yaml
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: my-app
spec:
  serviceName: "my-app"
  replicas: 3
  template:
    metadata:
      labels:
        app: my-app
      annotations:
        pod.alpha.kubernetes.io/initialized: "false"
...
...
...
```

设置注解后，如果创建了StatefulSet，您可以等待每个Pod来验证它是否正确初始化。StatefulSet将不会创建任何后续的Pods，直到在已经创建的每个Pod上将调试注解设置为`"true"` (或删除)。 您可以通过执行以下命令将注解设置为`"true"`：

```shell
kubectl annotate pods <pod-name> pod.alpha.kubernetes.io/initialized="true" --overwrite
```

### 接下来

点击链接[调试init-container](https://kubernetes.io/docs/tasks/troubleshoot/debug-init-containers/)，了解更多信息





## 使用crictl调试Kubernetes节点

**FEATURE STATE:** `Kubernetes v1.11` [稳定](https://v1-14.docs.kubernetes.io/zh/docs/tasks/debug-application-cluster/crictl/#)

`crictl` 是 CRI 兼容的容器运行时命令行接口。 您可以使用它来检查和调试 Kubernetes 节点上的容器运行时和应用程序。 `crictl`和它的源代码在 [cri-tools](https://github.com/kubernetes-incubator/cri-tools) 代码库.

### 准备开始

`crictl` 需要带有 CRI 运行时的 Linux 操作系统。

### 安装 crictl

您可以从 cri-tools [发布页面](https://github.com/kubernetes-incubator/cri-tools/releases)下载一个压缩的 `crictl` 归档文件，用于几种不同的架构。 下载与您的 kubernetes 版本相对应的版本。 提取它并将其移动到系统路径上的某个位置，例如`/usr/local/bin/`。

### 一般用法

`crictl` 命令有几个子命令和运行时参数。 有关详细信息，请使用 `crictl help` 或 `crictl <subcommand> help` 获取帮助信息。

`crictl` 默认连接到 `unix:///var/run/dockershim.sock`。 对于其他的运行时，您可以用多种不同的方法设置端点：

-   通过设置参数 `--runtime-endpoint` 和 `--image-endpoint`
-   通过设置环境变量 `CONTAINER_RUNTIME_ENDPOINT` 和 `IMAGE_SERVICE_ENDPOINT`
-   通过在配置文件中设置端点 `--config=/etc/crictl.yaml`

您还可以在连接到服务器并启用或禁用调试时指定超时值，方法是在配置文件中指定 `timeout` 或 `debug` 值，或者使用 `--timeout` 和 `--debug` 命令行参数。

要查看或编辑当前配置，请查看或编辑 `/etc/crictl.yaml` 的内容。

```sh
cat /etc/crictl.yaml
runtime-endpoint: unix:///var/run/dockershim.sock
image-endpoint: unix:///var/run/dockershim.sock
timeout: 10
debug: true
```

### crictl 命令示例

>   Warning:
>
>   如果使用 `crictl` 在正在运行的 Kubernetes 集群上创建 Pod 沙盒或容器，kubelet 最终将删除它们。 `crictl` 不是一个通用的工作流工具，而是一个对调试有用的工具。

#### 打印 Pod 清单

打印所有 Pod 的清单：

```bash
crictl pods
POD ID              CREATED              STATE               NAME                         NAMESPACE           ATTEMPT
926f1b5a1d33a       About a minute ago   Ready               sh-84d7dcf559-4r2gq          default             0
4dccb216c4adb       About a minute ago   Ready               nginx-65899c769f-wv2gp       default             0
a86316e96fa89       17 hours ago         Ready               kube-proxy-gblk4             kube-system         0
919630b8f81f1       17 hours ago         Ready               nvidia-device-plugin-zgbbv   kube-system         0
```

根据名称打印 Pod 清单：

```bash
crictl pods --name nginx-65899c769f-wv2gp
POD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT
4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0
```

根据标签打印 Pod 清单：

```bash
crictl pods --label run=nginx
POD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT
4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0
```

#### 打印镜像清单

打印所有镜像清单：

```bash
crictl images
IMAGE                                     TAG                 IMAGE ID            SIZE
busybox                                   latest              8c811b4aec35f       1.15MB
k8s-gcrio.azureedge.net/hyperkube-amd64   v1.10.3             e179bbfe5d238       665MB
k8s-gcrio.azureedge.net/pause-amd64       3.1                 da86e6ba6ca19       742kB
nginx                                     latest              cd5239a0906a6       109MB
```

根据仓库打印镜像清单：

```bash
crictl images nginx
IMAGE               TAG                 IMAGE ID            SIZE
nginx               latest              cd5239a0906a6       109MB
```

只打印镜像 ID：

```bash
crictl images -q
sha256:8c811b4aec35f259572d0f79207bc0678df4c736eeec50bc9fec37ed936a472a
sha256:e179bbfe5d238de6069f3b03fccbecc3fb4f2019af741bfff1233c4d7b2970c5
sha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e
sha256:cd5239a0906a6ccf0562354852fae04bc5b52d72a2aff9a871ddb6bd57553569
```

#### 打印容器清单

打印所有容器清单：

```bash
crictl ps -a
CONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT
1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   7 minutes ago       Running             sh                         1
9c5951df22c78       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   8 minutes ago       Exited              sh                         0
87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     8 minutes ago       Running             nginx                      0
1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   18 hours ago        Running             kube-proxy                 0
```

打印正在运行的容器清单：

```bash
crictl ps
CONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT
1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   6 minutes ago       Running             sh                         1
87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     7 minutes ago       Running             nginx                      0
1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   17 hours ago        Running             kube-proxy                 0
```

#### 在正在运行的容器上执行命令

```bash
crictl exec -i -t 1f73f2d81bf98 ls
bin   dev   etc   home  proc  root  sys   tmp   usr   var
```

#### 获取容器日志

获取容器的所有日志：

```bash
crictl logs 87d3992f84f74
10.240.0.96 - - [06/Jun/2018:02:45:49 +0000] "GET / HTTP/1.1" 200 612 "-" "curl/7.47.0" "-"
10.240.0.96 - - [06/Jun/2018:02:45:50 +0000] "GET / HTTP/1.1" 200 612 "-" "curl/7.47.0" "-"
10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] "GET / HTTP/1.1" 200 612 "-" "curl/7.47.0" "-"
```

获取最近的 `N` 行日志：

```bash
crictl logs --tail=1 87d3992f84f74
10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] "GET / HTTP/1.1" 200 612 "-" "curl/7.47.0" "-"
```

#### 运行 Pod 沙盒

用 `crictl` 运行 Pod 沙盒对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机地被 kubelet 停止和删除。

1.  编写下面的 JSON 文件：

    ```json
    {
        "metadata": {
            "name": "nginx-sandbox",
            "namespace": "default",
            "attempt": 1,
            "uid": "hdishd83djaidwnduwk28bcsb"
        },
        "logDirectory": "/tmp",
        "linux": {
        }
    }
    ```

2.  使用 `crictl runp` 命令应用 JSON 文件并运行沙盒。

    ```bash
      crictl runp pod-config.json
    ```

    返回了沙盒的 ID。

#### 创建容器

用 `crictl` 创建容器对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机的被 kubelet 停止和删除。

1.  拉取 busybox 镜像

    ```bash
      crictl pull busybox
      Image is up to date for busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47
    ```

2.  创建 Pod 和容器的配置：

    **Pod 配置**：

    ```yaml
      {
          "metadata": {
              "name": "nginx-sandbox",
              "namespace": "default",
              "attempt": 1,
              "uid": "hdishd83djaidwnduwk28bcsb"
          },
          "log_directory": "/tmp",
          "linux": {
          }
      }
    ```

    **容器配置**：

    ```yaml
      {
        "metadata": {
            "name": "busybox"
        },
        "image":{
            "image": "busybox"
        },
        "command": [
            "top"
        ],
        "log_path":"busybox/0.log",
        "linux": {
        }
      }
    ```

3.  创建容器，传递先前创建的 Pod 的 ID、容器配置文件和 Pod 配置文件。返回容器的 ID。

    ```bash
      crictl create f84dd361f8dc51518ed291fbadd6db537b0496536c1d2d6c05ff943ce8c9a54f container-config.json pod-config.json
    ```

4.  查询所有容器并确认新创建的容器状态为 `Created`。

    ```bash
      crictl ps -a
    ```

    ```none
      CONTAINER ID        IMAGE               CREATED             STATE               NAME                ATTEMPT
      3e025dd50a72d       busybox             32 seconds ago      Created             busybox             0
    ```

#### 启动容器

要启动容器，要将容器 ID 传给 `crictl start`：

```bash
crictl start 3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60
3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60
```

确认容器的状态为 `Running`。

```bash
crictl ps
CONTAINER ID        IMAGE               CREATED              STATE               NAME                ATTEMPT
3e025dd50a72d       busybox             About a minute ago   Running             busybox             0
```

更多信息请参考 [kubernetes-incubator/cri-tools](https://github.com/kubernetes-incubator/cri-tools)。





## 确定pod失败的原因

本文介绍如何编写和读取容器的终止消息。

终止消息为容器提供了一种方法，可以将有关致命事件的信息写入某个位置，在该位置可以通过仪表板和监控软件等工具轻松检索和显示致命事件。 在大多数情况下，您放入终止消息中的信息也应该写入[常规 Kubernetes 日志](https://v1-14.docs.kubernetes.io/docs/concepts/cluster-administration/logging/)。

### 准备开始

一个集群。

### 读写终止消息

在本练习中，您将创建运行一个容器的 Pod。 配置文件指定在容器启动时要运行的命令。

[`debug/termination.yaml`](https://raw.githubusercontent.com/kubernetes/website/master/content/zh/examples/debug/termination.yaml)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: termination-demo
spec:
  containers:
  - name: termination-demo-container
    image: debian
    command: ["/bin/sh"]
    args: ["-c", "sleep 10 && echo Sleep expired > /dev/termination-log"]
```

1.  基于 YAML 配置文件创建 Pod：

    ```
    kubectl create -f https://k8s.io/examples/debug/termination.yaml
    ```

    YAML 文件中，在 `cmd` 和 `args` 字段，你可以看到容器休眠 10 秒然后将 “Sleep expired” 写入 `/dev/termination-log` 文件。 容器写完 “Sleep expired” 消息后，它就终止了。

2.  显示 Pod 的信息：

    ```
    kubectl get pod termination-demo
    ```

    重复前面的命令直到 Pod 不再运行。

3.  显示 Pod 的详细信息：

    ```
    kubectl get pod --output=yaml
    ```

    输出结果包含 “Sleep expired” 消息：

    ```
    apiVersion: v1
    kind: Pod
    ...
        lastState:
          terminated:
            containerID: ...
            exitCode: 0
            finishedAt: ...
            message: |
              Sleep expired
            ...
    ```

4.  使用 Go 模板过滤输出结果，使其只含有终止消息：

    ```
    kubectl get pod termination-demo -o go-template="{{range .status.containerStatuses}}{{.lastState.terminated.message}}{{end}}"
    ```

### 定制终止消息

Kubernetes 从容器的 `terminationMessagePath` 字段中指定的终止消息文件中检索终止消息，默认值为 `/dev/termination-log`。 通过定制这个字段，您可以告诉 Kubernetes 使用不同的文件。 Kubernetes 使用指定文件中的内容在成功和失败时填充容器的状态消息。

在下例中，容器将终止消息写入 `/tmp/my-log` 给 Kubernetes 来接收：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: msg-path-demo
spec:
  containers:
  - name: msg-path-demo-container
    image: debian
    terminationMessagePath: "/tmp/my-log"
```

此外，用户可以设置容器的 `terminationMessagePolicy` 字段，以便进一步自定义。 此字段默认为 “`File`“，这意味着仅从终止消息文件中检索终止消息。 通过将 `terminationMessagePolicy` 设置为 “`FallbackToLogsOnError`“，你就可以告诉 Kubernetes，在容器因错误退出时，如果终止消息文件为空，则使用容器日志输出的最后一块作为终止消息。 日志输出限制为 2048 字节或 80 行，以较小者为准。

### 接下来

-   参考[容器](https://v1-14.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.14/#container-v1-core)的 `terminationMessagePath` 字段。
-   了解[接收日志](https://v1-14.docs.kubernetes.io/docs/concepts/cluster-administration/logging/)。
-   了解 [Go 模版](https://golang.org/pkg/text/template/)。





## 本地开发和调试服务

Kubernetes 应用程序通常由多个独立的服务组成，每个服务都在自己的容器中运行。 在远端的 Kubernetes 集群上开发和调试这些服务可能很麻烦，需要[在运行的容器上打开 shell](https://v1-14.docs.kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/)，然后在远端 shell 中运行您所需的工具。

`telepresence` 是一种工具，用于在本地轻松开发和调试服务，同时将服务代理到远程 Kubernetes 集群。 使用 `telepresence` 可以为本地服务使用自定义工具（如调试器和 IDE），并提供对 Configmap、Secrets 和远程集群上运行的服务的完全访问。

本文档描述如何在本地使用 `telepresence` 开发和调试远程集群上运行的服务。

### 准备开始

-   Kubernetes 集群安装完毕
-   配置好 `kubectl` 与集群交互
-   [Telepresence](https://www.telepresence.io/reference/install) 安装完毕

打开终端，不带参数运行 `telepresence`，以打开 `telepresence` shell。这个 shell 在本地运行，使您可以完全访问本地文件系统。

`telepresence` shell 的使用方式多种多样。 例如，在你的笔记本电脑上写一个 shell 脚本，然后直接在 shell 中实时运行它。 您也可以在远端 shell 上执行此操作，但这样可能无法使用首选的代码编辑器，并且在容器终止时脚本将被删除。

### 开发和调试现有的服务

在 Kubernetes 上开发应用程序时，通常对单个服务进行编程或调试。 服务可能需要访问其他服务以进行测试和调试。 一种选择是使用连续部署管道，但即使最快的部署管道也会在程序或调试周期中引入延迟。

使用 `--swap-deployment` 选项将现有部署与 Telepresence 代理交换。交换允许您在本地运行服务并能够连接到远端的 Kubernetes 集群。远端的集群中的服务现在就可以访问本地运行的实例。

到运行 telepresence 并带有 `--swap-deployment` 选项，请输入：

```
telepresence --swap-deployment $DEPLOYMENT_NAME
```

这里的 $DEPLOYMENT_NAME 是您现有的部署名称。

运行此命令将生成 shell。在 shell 中，启动您的服务。 然后，您就可以在本地对源代码进行编辑、保存并能看到更改立即生效。您还可以在调试器或任何其他本地开发工具中运行服务。

### 接下来

如果您对实践教程感兴趣，请查看[本教程](https://cloud.google.com/community/tutorials/developing-services-with-k8s)，其中介绍了在 Google Kubernetes Engine 上本地开发 Guestbook 应用程序。

Telepresence 有[多种代理选项](https://www.telepresence.io/reference/methods)，以满足您的各种情况。

要了解更多信息，请访问 [Telepresence 网站](https://www.telepresence.io/)。





## Stackdriver中的事件

Kubernetes 事件是一种对象，它为用户提供了洞察集群内发生的事情的能力，例如调度程序做出了什么决定，或者为什么某些 Pod 被逐出节点。 您可以在[应用程序自检和调试](https://v1-14.docs.kubernetes.io/docs/tasks/debug-application-cluster/debug-application-introspection/)中阅读有关使用事件调试应用程序的更多信息。

由于事件是 API 对象，因此它们存储在主节点上的 apiserver 中。 为了避免主节点磁盘空间被填满，将强制执行保留策略：在最后一次事件发生一小时后删除事件。 为了提供更长的历史记录和聚合能力，应该安装第三方解决方案来捕获事件。

本文描述了一个将 Kubernetes 事件导出为 Stackdriver Logging 的解决方案，在这里可以对它们进行处理和分析。

>   Note:
>
>   不能保证集群中发生的所有事件都将导出到 Stackdriver。 事件不能导出的一种可能情况是事件导出器没有运行（例如，在重新启动或升级期间）。 在大多数情况下，可以将事件用于设置 [metrics][sdLogMetrics] 和 [alerts][sdAlerts] 等目的，但您应该注意潜在的不准确性。

### 部署

#### Google Kubernetes Engine

在 Google Kubernetes Engine 中，如果启用了云日志，那么事件导出器默认部署在主节点运行版本为 1.7 及更高版本的集群中。 为了防止干扰您的工作负载，事件导出器没有设置资源，并且处于尽力而为的 QoS 类型中，这意味着它将在资源匮乏的情况下第一个被杀死。 如果要导出事件，请确保有足够的资源给事件导出器 Pod 使用。 这可能会因为工作负载的不同而有所不同，但平均而言，需要大约 100MB 的内存和 100m 的 CPU。

#### 部署到现有集群

使用下面的命令将事件导出器部署到您的集群：

```shell
kubectl create -f https://k8s.io/examples/debug/event-exporter.yaml
```

由于事件导出器访问 Kubernetes API，因此它需要权限才能访问。 以下的部署配置为使用 RBAC 授权。 它设置服务帐户和集群角色绑定，以允许事件导出器读取事件。 为了确保事件导出器 Pod 不会从节点中退出，您可以另外设置资源请求。 如前所述，100MB 内存和 100m CPU 应该就足够了。

[`debug/event-exporter.yaml` ](https://raw.githubusercontent.com/kubernetes/website/master/content/zh/examples/debug/event-exporter.yaml)

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: event-exporter-sa
  namespace: default
  labels:
    app: event-exporter
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: event-exporter-rb
  labels:
    app: event-exporter
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- kind: ServiceAccount
  name: event-exporter-sa
  namespace: default
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: event-exporter-v0.2.3
  namespace: default
  labels:
    app: event-exporter
spec:
  selector:
    matchLabels:
      app: event-exporter
  replicas: 1
  template:
    metadata:
      labels:
        app: event-exporter
    spec:
      serviceAccountName: event-exporter-sa
      containers:
      - name: event-exporter
        image: k8s.gcr.io/event-exporter:v0.2.3
        command:
        - '/event-exporter'
      terminationGracePeriodSeconds: 30
```

### 用户指南

事件在 Stackdriver Logging 中被导出到 `GKE Cluster` 资源。 您可以通过从可用资源的下拉菜单中选择适当的选项来找到它们：

![Events location in the Stackdriver Logging interface](https://v1-14.docs.kubernetes.io/images/docs/stackdriver-event-exporter-resource.png)

您可以使用 Stackdriver Logging 的[过滤机制](https://cloud.google.com/logging/docs/view/advanced_filters)基于事件对象字段进行过滤。 例如，下面的查询将显示调度程序中有关 Deployment `nginx-deployment` 中的 Pod 的事件：

```
resource.type="gke_cluster"
jsonPayload.kind="Event"
jsonPayload.source.component="default-scheduler"
jsonPayload.involvedObject.name:"nginx-deployment"
```

![Filtered events in the Stackdriver Logging interface](https://v1-14.docs.kubernetes.io/images/docs/stackdriver-event-exporter-filter.png)





## 获取正在运行的容器的shell

本文介绍怎样使用 `kubectl exec` 命令获取正在运行容器的 Shell。

### 准备开始

你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。 如果你还没有集群，你可以通过 [Minikube](https://v1-14.docs.kubernetes.io/docs/getting-started-guides/minikube) 构建一 个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：

-   [Katacoda](https://www.katacoda.com/courses/kubernetes/playground)
-   [Play with Kubernetes](http://labs.play-with-k8s.com/) –>

To check the version, enter `kubectl version`.

### 获取容器的 Shell

在本练习中，你将创建包含一个容器的 Pod。容器运行 nginx 镜像。下面是 Pod 的配置文件：

[`application/shell-demo.yaml`](https://raw.githubusercontent.com/kubernetes/website/master/content/zh/examples/application/shell-demo.yaml)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: shell-demo
spec:
  volumes:
  - name: shared-data
    emptyDir: {}
  containers:
  - name: nginx
    image: nginx
    volumeMounts:
    - name: shared-data
      mountPath: /usr/share/nginx/html
```

创建 Pod：

```shell
kubectl create -f https://k8s.io/examples/application/shell-demo.yaml
```

检查容器是否运行正常：

```shell
kubectl get pod shell-demo
```

获取正在运行容器的 Shell：

```shell
kubectl exec -it shell-demo -- /bin/bash
```

>   Note:
>
>   双破折号 “–” 用于将要传递给命令的参数与 kubectl 的参数分开。 note >}}
>
在 shell 中，打印根目录：

```shell
root@shell-demo:/# ls /
```

在 shell 中，实验其他命令。下面是一些示例：

```shell
root@shell-demo:/# ls /
root@shell-demo:/# cat /proc/mounts
root@shell-demo:/# cat /proc/1/maps
root@shell-demo:/# apt-get update
root@shell-demo:/# apt-get install -y tcpdump
root@shell-demo:/# tcpdump
root@shell-demo:/# apt-get install -y lsof
root@shell-demo:/# lsof
root@shell-demo:/# apt-get install -y procps
root@shell-demo:/# ps aux
root@shell-demo:/# ps aux | grep nginx
```

### 编写 nginx 的 根页面

在看一下 Pod 的配置文件。该 Pod 有个 `emptyDir` 卷，容器将该卷挂载到了 `/usr/share/nginx/html`。

在 shell 中，在 `/usr/share/nginx/html` 目录创建一个 `index.html 文件：

```shell
root@shell-demo:/# echo Hello shell demo > /usr/share/nginx/html/index.html
```

在 shell 中，向 nginx 服务器发送 GET 请求：

```shell
root@shell-demo:/# apt-get update
root@shell-demo:/# apt-get install curl
root@shell-demo:/# curl localhost
```

输出结果显示了你在 `index.html` 中写入的文本。

```shell
Hello shell demo
```

当用完 shell 后，输入 `exit` 退出。

### 在容器中运行单个命令

在普通的命令窗口（而不是 shell）中，打印环境运行容器中的变量：

```shell
kubectl exec shell-demo env
```

实验运行其他命令。下面是一些示例：

```shell
kubectl exec shell-demo ps aux
kubectl exec shell-demo ls /
kubectl exec shell-demo cat /proc/1/mounts
```

### 当 Pod 包含多个容器时打开 shell

如果 Pod 有多个容器，`--container` 或者 `-c` 可以在 `kubectl exec` 命令中指定容器。 例如，您有个名为 my-pod 的容器，该 Pod 有两个容器分别为 main-app 和 healper-app。 下面的命令将会打开一个 shell 访问 main-app 容器。

```shell
kubectl exec -it my-pod --container main-app -- /bin/bash
```

### 接下来

-   [kubectl exec](https://v1-14.docs.kubernetes.io/docs/reference/generated/kubectl/kubectl-commands/#exec)





## 使用Elasticsearch和Kibana进行日志记录

在 Google Compute Engine (GCE) 平台上，默认的日志管理支持目标是 [Stackdriver Logging](https://cloud.google.com/logging/)，在 [使用 Stackdriver Logging 管理日志](https://v1-14.docs.kubernetes.io/docs/user-guide/logging/stackdriver)中详细描述了这一点。

本文介绍了如何设置一个集群，将日志导入[Elasticsearch](https://www.elastic.co/products/elasticsearch)，并使用 [Kibana](https://www.elastic.co/products/kibana) 查看日志，作为在 GCE 上运行应用时使用 Stackdriver Logging 管理日志的替代方案。

>   Note:
>
>   您不能在 Google Kubernetes Engine 平台运行的 Kubernetes 集群上自动的部署 Elasticsearch 和 Kibana。您必须手动部署它们。

-   [接下来](https://v1-14.docs.kubernetes.io/zh/docs/tasks/debug-application-cluster/logging-elasticsearch-kibana/#%e6%8e%a5%e4%b8%8b%e6%9d%a5)

要使用 Elasticsearch 和 Kibana 处理集群日志，您应该在使用 kube-up.sh 脚本创建集群时设置下面所示的环境变量：

```shell
KUBE_LOGGING_DESTINATION=elasticsearch
```

您还应该确保设置了 `KUBE_ENABLE_NODE_LOGGING=true` （这是 GCE 平台的默认设置）。

现在，当您创建集群时，将有一条消息将指示每个节点上运行的 Fluentd 日志收集守护进程以 ElasticSearch 为日志输出目标：

```shell
$ cluster/kube-up.sh
...
Project: kubernetes-satnam
Zone: us-central1-b
... calling kube-up
Project: kubernetes-satnam
Zone: us-central1-b
+++ Staging server tars to Google Storage: gs://kubernetes-staging-e6d0e81793/devel
+++ kubernetes-server-linux-amd64.tar.gz uploaded (sha1 = 6987c098277871b6d69623141276924ab687f89d)
+++ kubernetes-salt.tar.gz uploaded (sha1 = bdfc83ed6b60fa9e3bff9004b542cfc643464cd0)
Looking for already existing resources
Starting master and configuring firewalls
Created [https://www.googleapis.com/compute/v1/projects/kubernetes-satnam/zones/us-central1-b/disks/kubernetes-master-pd].
NAME                 ZONE          SIZE_GB TYPE   STATUS
kubernetes-master-pd us-central1-b 20      pd-ssd READY
Created [https://www.googleapis.com/compute/v1/projects/kubernetes-satnam/regions/us-central1/addresses/kubernetes-master-ip].
+++ Logging using Fluentd to elasticsearch
```

每个节点的 Fluentd pod、Elasticsearch pod 和 Kibana pod 都应该在集群启动后不久运行在 kube-system 命名空间中。

```shell
$ kubectl get pods --namespace=kube-system
NAME                                           READY     STATUS    RESTARTS   AGE
elasticsearch-logging-v1-78nog                 1/1       Running   0          2h
elasticsearch-logging-v1-nj2nb                 1/1       Running   0          2h
fluentd-elasticsearch-kubernetes-node-5oq0     1/1       Running   0          2h
fluentd-elasticsearch-kubernetes-node-6896     1/1       Running   0          2h
fluentd-elasticsearch-kubernetes-node-l1ds     1/1       Running   0          2h
fluentd-elasticsearch-kubernetes-node-lz9j     1/1       Running   0          2h
kibana-logging-v1-bhpo8                        1/1       Running   0          2h
kube-dns-v3-7r1l9                              3/3       Running   0          2h
monitoring-heapster-v4-yl332                   1/1       Running   1          2h
monitoring-influx-grafana-v1-o79xf             2/2       Running   0          2h
```

`fluentd-elasticsearch` pod 从每个节点收集日志并将其发送到 `elasticsearch-logging`pods，该 pod 是名为 `elasticsearch-logging` 的[服务](https://v1-14.docs.kubernetes.io/docs/concepts/services-networking/service/)的一部分。 这些 ElasticSearch pod 存储日志，并通过 REST API 将其公开。 `kibana-logging` pod 提供了一个用于读取 ElasticSearch 中存储的日志的 Web UI，它是名为 `kibana-logging` 的服务的一部分。

Elasticsearch 和 Kibana 服务都位于 `kube-system` 命名空间中，并且没有通过可公开访问的 IP 地址直接暴露。 要访问它们，请参照[访问集群中运行的服务](https://v1-14.docs.kubernetes.io/docs/concepts/cluster-administration/access-cluster/#accessing-services-running-on-the-cluster)的说明进行操作。

如果你想在浏览器中访问 `elasticsearch-logging` 服务，你将看到类似下面的状态页面：

![Elasticsearch Status](https://v1-14.docs.kubernetes.io/images/docs/es-browser.png)

现在你可以直接在浏览器中输入 Elasticsearch 查询，如果你愿意的话。 请参考 [Elasticsearch 的文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-uri-request.html) 以了解这样做的更多细节。

或者，您可以使用 Kibana 查看集群的日志（再次使用[访问集群中运行的服务的说明](https://v1-14.docs.kubernetes.io/docs/user-guide/accessing-the-cluster/#accessing-services-running-on-the-cluster)）。 第一次访问 Kibana URL 时，将显示一个页面，要求您配置所接收日志的视图。 选择时间序列值的选项，然后选择 `@timestamp`。 在下面的页面中选择 `Discover` 选项卡，然后您应该能够看到所摄取的日志。 您可以将刷新间隔设置为 5 秒，以便定期刷新日志。

以下是从 Kibana 查看器中摄取日志的典型视图：

![Kibana logs](https://v1-14.docs.kubernetes.io/images/docs/kibana-logs.png)

### 接下来

Kibana 为浏览您的日志提供了各种强大的选项！有关如何深入研究它的一些想法，请查看 [Kibana 的文档](https://www.elastic.co/guide/en/kibana/current/discover.html)。





## （未翻译）使用Stackdriver进行日志记录

Before reading this page, it’s highly recommended to familiarize yourself with the [overview of logging in Kubernetes](https://kubernetes.io/docs/concepts/cluster-administration/logging).

>   **Note:** By default, Stackdriver logging collects only your container’s standard output and standard error streams. To collect any logs your application writes to a file (for example), see the [sidecar approach](https://kubernetes.io/docs/concepts/cluster-administration/logging#sidecar-container-with-a-logging-agent) in the Kubernetes logging overview.

### Deploying

To ingest logs, you must deploy the Stackdriver Logging agent to each node in your cluster. The agent is a configured `fluentd` instance, where the configuration is stored in a `ConfigMap` and the instances are managed using a Kubernetes `DaemonSet`. The actual deployment of the `ConfigMap` and `DaemonSet` for your cluster depends on your individual cluster setup.

#### Deploying to a new cluster

##### Google Kubernetes Engine

Stackdriver is the default logging solution for clusters deployed on Google Kubernetes Engine. Stackdriver Logging is deployed to a new cluster by default unless you explicitly opt-out.

##### Other platforms

To deploy Stackdriver Logging on a *new* cluster that you’re creating using `kube-up.sh`, do the following:

1.  Set the `KUBE_LOGGING_DESTINATION` environment variable to `gcp`.
2.  **If not running on GCE**, include the `beta.kubernetes.io/fluentd-ds-ready=true` in the `KUBE_NODE_LABELS` variable.

Once your cluster has started, each node should be running the Stackdriver Logging agent. The `DaemonSet` and `ConfigMap` are configured as addons. If you’re not using `kube-up.sh`, consider starting a cluster without a pre-configured logging solution and then deploying Stackdriver Logging agents to the running cluster.

>   **Warning:** The Stackdriver logging daemon has known issues on platforms other than Google Kubernetes Engine. Proceed at your own risk.

#### Deploying to an existing cluster

1.  Apply a label on each node, if not already present.

    The Stackdriver Logging agent deployment uses node labels to determine to which nodes it should be allocated. These labels were introduced to distinguish nodes with the Kubernetes version 1.6 or higher. If the cluster was created with Stackdriver Logging configured and node has version 1.5.X or lower, it will have fluentd as static pod. Node cannot have more than one instance of fluentd, therefore only apply labels to the nodes that don’t have fluentd pod allocated already. You can ensure that your node is labelled properly by running `kubectl describe` as follows:

    ```
    kubectl describe node $NODE_NAME
    ```

    The output should be similar to this:

    ```
    Name:           NODE_NAME
    Role:
    Labels:         beta.kubernetes.io/fluentd-ds-ready=true
    ...
    ```

    Ensure that the output contains the label `beta.kubernetes.io/fluentd-ds-ready=true`. If it is not present, you can add it using the `kubectl label` command as follows:

    ```
    kubectl label node $NODE_NAME beta.kubernetes.io/fluentd-ds-ready=true
    ```

    >   **Note:** If a node fails and has to be recreated, you must re-apply the label to the recreated node. To make this easier, you can use Kubelet’s command-line parameter for applying node labels in your node startup script.

2.  Deploy a `ConfigMap` with the logging agent configuration by running the following command:

    ```
    kubectl apply -f https://k8s.io/examples/debug/fluentd-gcp-configmap.yaml
    ```

    The command creates the `ConfigMap` in the `default` namespace. You can download the file manually and change it before creating the `ConfigMap` object.

3.  Deploy the logging agent `DaemonSet` by running the following command:

    ```
    kubectl apply -f https://k8s.io/examples/debug/fluentd-gcp-ds.yaml
    ```

    You can download and edit this file before using it as well.

### Verifying your Logging Agent Deployment

After Stackdriver `DaemonSet` is deployed, you can discover logging agent deployment status by running the following command:

```shell
kubectl get ds --all-namespaces
```

If you have 3 nodes in the cluster, the output should looks similar to this:

```
NAMESPACE     NAME               DESIRED   CURRENT   READY     NODE-SELECTOR                              AGE
...
default       fluentd-gcp-v2.0   3         3         3         beta.kubernetes.io/fluentd-ds-ready=true   5m
...
```

To understand how logging with Stackdriver works, consider the following synthetic log generator pod specification [counter-pod.yaml](https://kubernetes.io/examples/debug/counter-pod.yaml):



```yaml
debug/counter-pod.yaml 

apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox
    args: [/bin/sh, -c,
            'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done']
```

This pod specification has one container that runs a bash script that writes out the value of a counter and the datetime once per second, and runs indefinitely. Let’s create this pod in the default namespace.

```shell
kubectl apply -f https://k8s.io/examples/debug/counter-pod.yaml
```

You can observe the running pod:

```shell
kubectl get pods
NAME                                           READY     STATUS    RESTARTS   AGE
counter                                        1/1       Running   0          5m
```

For a short period of time you can observe the ‘Pending’ pod status, because the kubelet has to download the container image first. When the pod status changes to `Running` you can use the `kubectl logs` command to view the output of this counter pod.

```shell
kubectl logs counter
0: Mon Jan  1 00:00:00 UTC 2001
1: Mon Jan  1 00:00:01 UTC 2001
2: Mon Jan  1 00:00:02 UTC 2001
...
```

As described in the logging overview, this command fetches log entries from the container log file. If the container is killed and then restarted by Kubernetes, you can still access logs from the previous container. However, if the pod is evicted from the node, log files are lost. Let’s demonstrate this by deleting the currently running counter container:

```shell
kubectl delete pod counter
pod "counter" deleted
```

and then recreating it:

```shell
kubectl create -f https://k8s.io/examples/debug/counter-pod.yaml
pod/counter created
```

After some time, you can access logs from the counter pod again:

```shell
kubectl logs counter
0: Mon Jan  1 00:01:00 UTC 2001
1: Mon Jan  1 00:01:01 UTC 2001
2: Mon Jan  1 00:01:02 UTC 2001
...
```

As expected, only recent log lines are present. However, for a real-world application you will likely want to be able to access logs from all containers, especially for the debug purposes. This is exactly when the previously enabled Stackdriver Logging can help.

### Viewing logs

Stackdriver Logging agent attaches metadata to each log entry, for you to use later in queries to select only the messages you’re interested in: for example, the messages from a particular pod.

The most important pieces of metadata are the resource type and log name. The resource type of a container log is `container`, which is named `GKE Containers` in the UI (even if the Kubernetes cluster is not on Google Kubernetes Engine). The log name is the name of the container, so that if you have a pod with two containers, named `container_1` and `container_2` in the spec, their logs will have log names `container_1` and `container_2`respectively.

System components have resource type `compute`, which is named `GCE VM Instance` in the interface. Log names for system components are fixed. For a Google Kubernetes Engine node, every log entry from a system component has one of the following log names:

-   docker
-   kubelet
-   kube-proxy

You can learn more about viewing logs on [the dedicated Stackdriver page](https://cloud.google.com/logging/docs/view/logs_viewer).

One of the possible ways to view logs is using the [`gcloud logging`](https://cloud.google.com/logging/docs/api/gcloud-logging) command line interface from the [Google Cloud SDK](https://cloud.google.com/sdk/). It uses Stackdriver Logging [filtering syntax](https://cloud.google.com/logging/docs/view/advanced_filters) to query specific logs. For example, you can run the following command:

```none
gcloud beta logging read 'logName="projects/$YOUR_PROJECT_ID/logs/count"' --format json | jq '.[].textPayload'
...
"2: Mon Jan  1 00:01:02 UTC 2001\n"
"1: Mon Jan  1 00:01:01 UTC 2001\n"
"0: Mon Jan  1 00:01:00 UTC 2001\n"
...
"2: Mon Jan  1 00:00:02 UTC 2001\n"
"1: Mon Jan  1 00:00:01 UTC 2001\n"
"0: Mon Jan  1 00:00:00 UTC 2001\n"
```

As you can see, it outputs messages for the count container from both the first and second runs, despite the fact that the kubelet already deleted the logs for the first container.

#### Exporting logs

You can export logs to [Google Cloud Storage](https://cloud.google.com/storage/) or to [BigQuery](https://cloud.google.com/bigquery/) to run further analysis. Stackdriver Logging offers the concept of sinks, where you can specify the destination of log entries. More information is available on the Stackdriver [Exporting Logs page](https://cloud.google.com/logging/docs/export/configure_export_v2).

### Configuring Stackdriver Logging Agents

Sometimes the default installation of Stackdriver Logging may not suit your needs, for example:

-   You may want to add more resources because default performance doesn’t suit your needs.
-   You may want to introduce additional parsing to extract more metadata from your log messages, like severity or source code reference.
-   You may want to send logs not only to Stackdriver or send it to Stackdriver only partially.

In this case you need to be able to change the parameters of `DaemonSet` and `ConfigMap`.

#### Prerequisites

If you’re using GKE and Stackdriver Logging is enabled in your cluster, you cannot change its configuration, because it’s managed and supported by GKE. However, you can disable the default integration and deploy your own.

>   **Note:** You will have to support and maintain a newly deployed configuration yourself: update the image and configuration, adjust the resources and so on.

To disable the default logging integration, use the following command:

```
gcloud beta container clusters update --logging-service=none CLUSTER
```

You can find notes on how to then install Stackdriver Logging agents into a running cluster in the [Deploying section](https://kubernetes.io/docs/tasks/debug-application-cluster/logging-stackdriver/#deploying).

#### Changing `DaemonSet` parameters

When you have the Stackdriver Logging `DaemonSet` in your cluster, you can just modify the `template` field in its spec, daemonset controller will update the pods for you. For example, let’s assume you’ve just installed the Stackdriver Logging as described above. Now you want to change the memory limit to give fluentd more memory to safely process more logs.

Get the spec of `DaemonSet` running in your cluster:

```shell
kubectl get ds fluentd-gcp-v2.0 --namespace kube-system -o yaml > fluentd-gcp-ds.yaml
```

Then edit resource requirements in the spec file and update the `DaemonSet` object in the apiserver using the following command:

```shell
kubectl replace -f fluentd-gcp-ds.yaml
```

After some time, Stackdriver Logging agent pods will be restarted with the new configuration.

#### Changing fluentd parameters

Fluentd configuration is stored in the `ConfigMap` object. It is effectively a set of configuration files that are merged together. You can learn about fluentd configuration on the [official site](http://docs.fluentd.org/).

Imagine you want to add a new parsing logic to the configuration, so that fluentd can understand default Python logging format. An appropriate fluentd filter looks similar to this:

```
<filter reform.**>
  type parser
  format /^(?<severity>\w):(?<logger_name>\w):(?<log>.*)/
  reserve_data true
  suppress_parse_error_log true
  key_name log
</filter>
```

Now you have to put it in the configuration and make Stackdriver Logging agents pick it up. Get the current version of the Stackdriver Logging `ConfigMap` in your cluster by running the following command:

```shell
kubectl get cm fluentd-gcp-config --namespace kube-system -o yaml > fluentd-gcp-configmap.yaml
```

Then in the value of the key `containers.input.conf` insert a new filter right after the `source` section.

>   **Note:** Order is important.

Updating `ConfigMap` in the apiserver is more complicated than updating `DaemonSet`. It’s better to consider `ConfigMap` to be immutable. Then, in order to update the configuration, you should create `ConfigMap` with a new name and then change `DaemonSet` to point to it using [guide above](https://kubernetes.io/docs/tasks/debug-application-cluster/logging-stackdriver/#changing-daemonset-parameters).

#### Adding fluentd plugins

Fluentd is written in Ruby and allows to extend its capabilities using [plugins](http://www.fluentd.org/plugins). If you want to use a plugin, which is not included in the default Stackdriver Logging container image, you have to build a custom image. Imagine you want to add Kafka sink for messages from a particular container for additional processing. You can re-use the default [container image sources](https://git.k8s.io/contrib/fluentd/fluentd-gcp-image) with minor changes:

-   Change Makefile to point to your container repository, e.g. `PREFIX=gcr.io/<your-project-id>`.
-   Add your dependency to the Gemfile, for example `gem 'fluent-plugin-kafka'`.

Then run `make build push` from this directory. After updating `DaemonSet` to pick up the new image, you can use the plugin you installed in the fluentd configuration.





## 监测节点健康状态

*节点问题探测器* 是一个 [DaemonSet](https://v1-14.docs.kubernetes.io/docs/concepts/workloads/controllers/daemonset/) 用来监控节点健康。它从各种守护进程收集节点问题，并以[NodeCondition](https://v1-14.docs.kubernetes.io/docs/concepts/architecture/nodes/#condition) 和 [Event](https://v1-14.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.14/#event-v1-core) 的形式报告给 apiserver 。

它现在支持一些已知的内核问题检测，并将随着时间的推移，检测更多节点问题。

目前，Kubernetes 不会对节点问题检测器监测到的节点状态和事件采取任何操作。将来可能会引入一个补救系统来处理这些节点问题。

更多信息请参阅 [这里](https://github.com/kubernetes/node-problem-detector)。

### 准备开始

你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。 如果你还没有集群，你可以通过 [Minikube](https://v1-14.docs.kubernetes.io/docs/getting-started-guides/minikube) 构建一 个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：

-   [Katacoda](https://www.katacoda.com/courses/kubernetes/playground)
-   [Play with Kubernetes](http://labs.play-with-k8s.com/) –>

To check the version, enter `kubectl version`.

### 局限性

-   节点问题检测器的内核问题检测现在只支持基于文件类型的内核日志。 它不支持像 journald 这样的命令行日志工具。

-   节点问题检测器的内核问题检测对内核日志格式有一定要求，现在它只适用于 Ubuntu 和 Debian。但是，将其扩展为 [支持其它日志格式](https://v1-14.docs.kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#support-other-log-format) 也很容易。

### 在 GCE 集群中启用/禁用

节点问题检测器在 gce 集群中以[集群插件的形式](https://v1-14.docs.kubernetes.io/docs/setup/cluster-large/#addon-resources)默认启用。

您可以在运行 `kube-up.sh` 之前，以设置环境变量 `KUBE_ENABLE_NODE_PROBLEM_DETECTOR`的形式启用/禁用它。

### 在其它环境中使用

要在 GCE 之外的其他环境中启用节点问题检测器，您可以使用 `kubectl` 或插件 pod。

#### Kubectl

这是在 GCE 之外启动节点问题检测器的推荐方法。它的管理更加灵活，例如覆盖默认配置以使其适合您的环境或检测自定义节点问题。

-   **步骤 1:** `node-problem-detector.yaml`:

[`debug/node-problem-detector.yaml`](https://raw.githubusercontent.com/kubernetes/website/master/content/zh/examples/debug/node-problem-detector.yaml)

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-problem-detector-v0.1
  namespace: kube-system
  labels:
    k8s-app: node-problem-detector
    version: v0.1
    kubernetes.io/cluster-service: "true"
spec:
  selector:
    matchLabels:
      k8s-app: node-problem-detector  
      version: v0.1
      kubernetes.io/cluster-service: "true"
  template:
    metadata:
      labels:
        k8s-app: node-problem-detector
        version: v0.1
        kubernetes.io/cluster-service: "true"
    spec:
      hostNetwork: true
      containers:
      - name: node-problem-detector
        image: k8s.gcr.io/node-problem-detector:v0.1
        securityContext:
          privileged: true
        resources:
          limits:
            cpu: "200m"
            memory: "100Mi"
          requests:
            cpu: "20m"
            memory: "20Mi"
        volumeMounts:
        - name: log
          mountPath: /log
          readOnly: true
      volumes:
      - name: log
        hostPath:
          path: /var/log/
```

**请注意保证您的系统日志路径与您的 OS 发行版相对应。**

-   **步骤 2:** 执行 `kubectl` 来启动节点问题检测器：

```shell
 kubectl create -f https://k8s.io/examples/debug/node-problem-detector.yaml
```

#### 插件 Pod

这适用于拥有自己的集群引导程序解决方案的用户，并且不需要覆盖默认配置。 他们可以利用插件 Pod 进一步自动化部署。

只需创建 `node-problem-detector.yaml`，并将其放在主节点上的插件 pod 目录 `/etc/kubernetes/addons/node-problem-detector` 下。

### 覆盖配置文件

构建节点问题检测器的 docker 镜像时，会嵌入[默认配置](https://github.com/kubernetes/node-problem-detector/tree/v0.1/config)。

不过，您可以像下面这样使用 [ConfigMap](https://v1-14.docs.kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/) 将其覆盖：

-   **步骤 1:** 在 `config/` 中更改配置文件。
-   **步骤 2:** 使用 `kubectl create configmap node-problem-detector-config --from-file=config/`创建 `node-problem-detector-config` 。
-   **步骤 3:** 更改 `node-problem-detector.yaml` 以使用 ConfigMap:

[`debug/node-problem-detector-configmap.yaml`](https://raw.githubusercontent.com/kubernetes/website/master/content/zh/examples/debug/node-problem-detector-configmap.yaml)

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-problem-detector-v0.1
  namespace: kube-system
  labels:
    k8s-app: node-problem-detector
    version: v0.1
    kubernetes.io/cluster-service: "true"
spec:
  selector:
    matchLabels:
      k8s-app: node-problem-detector  
      version: v0.1
      kubernetes.io/cluster-service: "true"
  template:
    metadata:
      labels:
        k8s-app: node-problem-detector
        version: v0.1
        kubernetes.io/cluster-service: "true"
    spec:
      hostNetwork: true
      containers:
      - name: node-problem-detector
        image: k8s.gcr.io/node-problem-detector:v0.1
        securityContext:
          privileged: true
        resources:
          limits:
            cpu: "200m"
            memory: "100Mi"
          requests:
            cpu: "20m"
            memory: "20Mi"
        volumeMounts:
        - name: log
          mountPath: /log
          readOnly: true
        - name: config # Overwrite the config/ directory with ConfigMap volume
          mountPath: /config
          readOnly: true
      volumes:
      - name: log
        hostPath:
          path: /var/log/
      - name: config # Define ConfigMap volume
        configMap:
          name: node-problem-detector-config
```

-   **步骤 4:** 使用新的 yaml 文件重新创建节点问题检测器：

```shell
 kubectl delete -f https://k8s.io/examples/debug/node-problem-detector.yaml # If you have a node-problem-detector running
 kubectl create -f https://k8s.io/examples/debug/node-problem-detector-configmap.yaml
```

**请注意，此方法仅适用于通过 kubectl 启动的节点问题检测器。**

由于插件管理器不支持ConfigMap，因此现在不支持对于作为集群插件运行的节点问题检测器的配置进行覆盖。

### 内核监视器

*内核监视器* 是节点问题检测器中的问题守护进程。它监视内核日志并按照预定义规则检测已知内核问题。

内核监视器根据 [`config/kernel-monitor.json`](https://github.com/kubernetes/node-problem-detector/blob/v0.1/config/kernel-monitor.json) 中的一组预定义规则列表匹配内核问题。 规则列表是可扩展的，您始终可以通过覆盖配置来扩展它。

#### 添加新的 NodeCondition

您可以使用新的状态描述来扩展 `config/kernel-monitor.json` 中的 `conditions` 字段以支持新的节点状态。

```json
{
  "type": "NodeConditionType",
  "reason": "CamelCaseDefaultNodeConditionReason",
  "message": "arbitrary default node condition message"
}
```

#### 检测新的问题

您可以使用新的规则描述来扩展 `config/kernel-monitor.json` 中的 `rules` 字段以检测新问题。

```json
{
  "type": "temporary/permanent",
  "condition": "NodeConditionOfPermanentIssue",
  "reason": "CamelCaseShortReason",
  "message": "regexp matching the issue in the kernel log"
}
```

#### 更改日志路径

不同操作系统发行版的内核日志的可能不同。 `config/kernel-monitor.json` 中的 `log` 字段是容器内的日志路径。您始终可以修改配置使其与您的 OS 发行版匹配。

#### 支持其它日志格式

内核监视器使用 [`Translator`] 插件将内核日志转换为内部数据结构。我们可以很容易为新的日志格式实现新的翻译器。

### 注意事项

我们建议在集群中运行节点问题检测器来监视节点运行状况。但是，您应该知道这将在每个节点上引入额外的资源开销。一般情况下没有影响，因为：

-   内核日志生成相对较慢。
-   节点问题检测器有资源限制。
-   即使在高负载下，资源使用也是可以接受的。 (参阅 [基准测试结果](https://github.com/kubernetes/node-problem-detector/issues/2#issuecomment-220255629))





## 资源度量管道

从 Kubernetes 1.8 版本开始，用户在 Kubernetes 中可以通过度量 API 获取资源使用度量（如容器 CPU 和内存使用率）。 这些度量可以由用户直接访问，例如使用 `kubectl top` 命令，也可以由集群中的控制器（例如 Pod 水平自动扩缩器）用来做决策。

### 度量 API

通过度量 API，您可以获得给定节点或给定 Pod 当前使用的资源数量。 此 API 不存储度量值，因此不可能获得 10 分钟前给定节点使用的资源数量。

度量 API 和其他 API 没有什么不同：

-   它可通过与 `/apis/metrics.k8s.io/` 路径下的其他 Kubernetes API 相同的端点来发现
-   它提供相同的安全性、可扩展性和可靠性保证

度量 API 是在 [k8s.io/metrics](https://github.com/kubernetes/metrics/blob/master/pkg/apis/metrics/v1beta1/types.go) 仓库进行定义的。您可以在那里找到该 API 相关的更多信息。

>   Note:
>
>   度量 API 要求在集群中部署度量服务器。否则它将不可用。

### 度量服务器

[指标服务器](https://github.com/kubernetes-incubator/metrics-server)是集群范围内的资源使用数据的聚合器。 从 Kubernetes 1.8 版本开始，它作为部署对象默认部署在由 `kube-up.sh` 脚本创建的集群中。 如果您使用了不同的 Kubernetes 安装机制，则可以使用提供的[部署 yaml](https://github.com/kubernetes%E5%AD%B5%E5%8C%96%E5%99%A8/metrics-server/tree/master/deploy)。 它在 Kubernetes 1.7 以上版本中被支持（请参见下面的详细信息）。

度量服务器通过 Summary API 获取度量值，该 API 由 [Kubelet](https://v1-14.docs.kubernetes.io/docs/admin/kubelet/) 在每个节点上进行暴露。

度量服务器通过 [Kubernetes 聚合器](https://v1-14.docs.kubernetes.io/docs/concepts/api-extension/apiserver-aggregation/)在主 API 服务器中注册，该聚合器是在 Kubernetes 1.7 版本中引入的。

进一步了解度量服务器请参考[设计文档](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/metrics-server.md)。





## 资源监控工具

要扩展应用程序并提供可靠的服务，您需要了解应用程序部署时的行为。 您可以通过检查容器、[pod](https://v1-14.docs.kubernetes.io/docs/user-guide/pods)、[服务](https://v1-14.docs.kubernetes.io/docs/user-guide/services) 和整个集群的特性来检查 Kubernetes 集群中的应用程序性能。 Kubernetes 在每一个级别上提供了关于应用程序资源使用的详细信息。 此信息允许您评估应用程序的性能，以及在何处可以消除瓶颈以提高整体性能。

在 Kubernetes 中，应用程序监控不依赖单个监控解决方案。 默认情况下，新集群上可以使用两个单独的管道来收集监控统计信息：

-   [**资源度量管道**](https://v1-14.docs.kubernetes.io/zh/docs/tasks/debug-application-cluster/resource-usage-monitoring/#resource-metrics-pipeline)提供了一组与集群组件（如 HorizontalPodautoScaler 控制器）以及 `kubectl top` 实用程序相关的有限度量。 这些度量由[度量服务器](https://github.com/kubernetes-incubator/metrics-server)收集，并通过 `metrics.k8s.io` API 公开。 `度量服务器`发现群集中的所有节点，并查询每个节点的 [Kubelet](https://v1-14.docs.kubernetes.io/docs/admin/kubelet) 以获取 CPU 和内存使用情况。 Kubelet 从 [cAdvisor](https://github.com/google/cadvisor) 获取数据。 `度量服务器`是一个轻量级的短期内存存储。

-   一个[**完整度量管道**](https://v1-14.docs.kubernetes.io/zh/docs/tasks/debug-application-cluster/resource-usage-monitoring/#full-metrics-pipelines)，如 Prometheus，可以让您访问更丰富的度量。 此外，Kubernetes 还可以根据集群的当前状态，使用 Pod 水平自动扩缩器等机制，通过自动调用扩展或调整集群来响应这些度量。 监控管道从 kubelet 获取度量，然后通过适配器将它们公开给 Kubernetes，方法是实现 `custom.metrics.k8s.io` 或 `external.metrics.k8s.io`API。

### 资源度量管道

#### Kubelet

Kubelet充当 Kubernetes 主节点和节点之间的桥梁。 它管理机器上运行的 Pod 和容器。 Kubelet 将每个 Pod 转换为它的组成容器，并从 cAdvisor 获取各个容器的使用统计信息。然后它通过一个 REST API 公开聚合的 Pod 资源使用统计信息。

#### cAdvisor

cAdvisor 是一个开源容器资源使用和性能分析代理。 它是专门为容器构造的，并原生支持 Docker 容器。 在 Kubernetes 中，cAdvisor 被集成到了 kubelet 二进制文件中。 cAdvisor 自动发现机器中的所有容器，并收集 CPU、内存、文件系统和网络使用统计信息。 cAdvisor 还通过分析机器上的 ‘root’ 容器来提供机器的总体使用情况。

在大多数 Kubernetes 集群中，cAdvisor 在端口 4194 上为机上容器提供了一个简单的用户界面。以下是 cAdvisor 的部分用户界面的快照，其中显示了机器的总体使用情况：

![cAdvisor](https://v1-14.docs.kubernetes.io/images/docs/cadvisor.png)

### 完整度量管道

现有许多用于 Kubernetes 的完整度量解决方案。

#### Prometheus

[Prometheus](https://prometheus.io/) 可以原生监控 Kubernetes、节点和 Prometheus 自身。 [Prometheus Operator](https://coreos.com/operators/prometheus/docs/latest/) 简化了 Kubernetes 上的 Prometheus 安装，并允许您使用 [Prometheus adapter](https://github.com/directxman12/k8s-prometheus-adapter) 为自定义度量 API 提供支持。 Prometheus 提供了一种强大的查询语言和一个内置的仪表板，用于查询和可视化您的数据。 Prometheus 也是支持 [Grafana](https://prometheus.io/docs/visualization/grafana/) 的数据源。

#### Google Cloud Monitoring

Google Cloud Monitoring 是一个托管的监控服务，您可以使用它对应用程序中的重要指标进行可视化和警报。 可以从 Kubernetes 收集度量，并且可以使用 [Cloud Monitoring Console](https://app.google.stackdriver.com/) 访问它们。 您可以创建和自定义仪表板，从而可视化从您的 Kubernetes 集群中收集的数据。

下面的视频介绍了如何配置和运行 Google Cloud Monitoring 支持的 Heapster：![Google Cloud Monitoring dashboard example](https://d33wubrfki0l68.cloudfront.net/06774a9a853dfbd9a7354cd90206dc95969a21a6/b54a7/images/docs/gcm.png)

##### Google Cloud Monitoring dashboard 示例

这个dashboard显示了集群级的资源使用。

### CronJob 监控

#### Kubernetes Job Monitor

使用 [Kubernetes Job Monitor](https://github.com/pietervogelaar/kubernetes-job-monitor) 仪表板，集群管理员可以看到哪些 job 在运行以及查看已完成 job 的状态。

#### New Recil Kubernetes 监控集成

[New Relic Kubernetes](https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/kubernetes-monitoring-integration)集成提高了对 Kubernetes 环境性能的可视性。 New Relic 的 Kubernetes 集成通过报告来自 Kubernetes 对象的指标，为容器编排层提供参数。 该集成让您可以深入了解 Kubernetes 节点、名称空间、部署、副本集、pod 和容器。

移动文字功能： 在预构建的仪表板中查看数据，以便立即了解 Kubernetes 环境信息。 根据自动报告的数据创建自己的自定义查询和图表。 对 Kubernetes 数据创建警告条件。 进一步了解该功能请参考这个[页面](https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/kubernetes-monitoring-integration)。





## 应用程序故障排查

本指南帮助用户来调试kubernetes上那些没有正常运行的应用。 本指南*不能*调试集群。如果想调试集群的话，请参阅[这里](https://kubernetes.io/docs/admin/cluster-troubleshooting)。

### 诊断问题

故障排查的第一步是先给问题分下类。这个问题是什么？Pods，Replication Controller或者Service？

-   [调试Pod](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/debug-application/#debugging-pods)
-   [调试副本控制器](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/debug-application/#debugging-replication-controllers)
-   [调试服务](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/debug-application/#debugging-services)

### 调试Pod

调试pod的第一步是看一下这个pod的信息，用如下命令查看一下pod的当前状态和最近的事件：

```shell
$ kubectl describe pods ${POD_NAME}
```

查看一下pod中的容器所处的状态。这些容器的状态都是`Running`吗？最近有没有重启过？

后面的调试都是要依靠pods的状态的。

#### pod停留在pending状态

如果一个pod卡在`Pending`状态，则表示这个pod没有被调度到一个节点上。通常这是因为资源不足引起的。
敲一下`kubectl describe ...`这个命令，输出的信息里面应该有显示为什么没被调度的原因。
常见原因如下：

-   **资源不足**:
    你可能耗尽了集群上所有的CPU和内存，此时，你需要删除pods，调整资源请求，或者增加节点。 更多信息请参阅[Compute Resources document](https://kubernetes.io/docs/user-guide/compute-resources/#my-pods-are-pending-with-event-message-failedscheduling)
-   **使用了hostPort**: 如果绑定一个pod到`hostPort`，那么能创建的pod个数就有限了。
    多数情况下，`hostPort`是非必要的，而应该采用服务来暴露pod。
    如果确实需要使用`hostPort`，那么能创建的pod的数量就是节点的个数。

#### pod停留在waiting状态

如果一个pod卡在`Waiting`状态，则表示这个pod已经调试到节点上，但是没有运行起来。
再次敲一下`kubectl describe ...`这个命令来查看相关信息。
最常见的原因是拉取镜像失败。可以通过以下三种方式来检查：

-   使用的镜像名字正确吗？
-   镜像仓库里有没有这个镜像？
-   用`docker pull <image>`命令手动拉下镜像试试。

#### pod处于crashing状态或者unhealthy

首先，看一下容器的log:

```shell
$ kubectl logs ${POD_NAME} ${CONTAINER_NAME}
```

如果容器是crashed的，用如下命令可以看到crash的log:

```shell
$ kubectl logs --previous ${POD_NAME} ${CONTAINER_NAME}
```

或者，用`exec`在容器内运行一些命令：

```shell
$ kubectl exec ${POD_NAME} -c ${CONTAINER_NAME} -- ${CMD} ${ARG1} ${ARG2} ... ${ARGN}
```

注意：当一个pod内只有一个容器时，可以不带参数`-c ${CONTAINER_NAME}`。

例如，名为Cassandra的pod，处于running态，要查看它的log，可运行如下命令：

```shell
$ kubectl exec cassandra -- cat /var/log/cassandra/system.log
```

如果以上方法都不起作用，找到这个pod所在的节点并用SSH登录进去做进一步的分析。
通常情况下，是不需要在Kubernetes API中再给出另外的工具的。
因此，如果你发现需要ssh进一个主机来分析问题时，请在GitHub上提一个特性请求，描述一个你的场景并说明为什么已经提供的工具不能满足需求。

#### pod处于running态，但是没有正常工作

如果创建的pod不符合预期，那么创建pod的描述文件应该是存在某种错误的，并且这个错误在创建pod时被忽略掉。
通常pod的定义中，章节被错误的嵌套，或者一个字段名字被写错，都可能会引起被忽略掉。
例如，希望在pod中用命令行执行某个命令，但是将`command`写成`commnd`，pod虽然可以创建，但命令并没有执行。

如何查出来哪里出错？
首先，删掉这个pod再重新创建一个，重创时，像下面这样带着`--validate`这个参数：
`kubectl create --validate -f mypod.yaml`，`command`写成`commnd`的拼写错误就会打印出来了。

```shell
I0805 10:43:25.129850   46757 schema.go:126] unknown field: commnd
I0805 10:43:25.129973   46757 schema.go:129] this may be a false alarm, see https://github.com/kubernetes/kubernetes/issues/6842
pods/mypod
```

如果上面方法没有看到相关异常的信息，那么接下来就要验证从apiserver获取到的pod是否与期望的一致，比如创建Pod的yaml文件是mypod.yaml。

运行如下命令来获取apiserver创建的pod信息并保存成一个文件：
`kubectl get pods/mypod -o yaml > mypod-on-apiserver.yaml`。

然后手动对这两个文件进行比较:
apiserver获得的yaml文件中的一些行，不在创建pod的yaml文件内，这是正常的。
如果创建Pod的yaml文件内的一些行，在piserver获得的yaml文件中不存在，可以说明创建pod的yaml中的定义有问题。

### 调试复制控制器(Replication Controllers)

RC相当简单。他们要么能创建pod，要么不能。如果不能创建pod，请参阅上述[Debugging Pods](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/debug-application/#debugging-pods)。

也可以使用`kubectl describe rc ${CONTROLLER_NAME}`命令来监视RC相关的事件。

### 调试服务(Services)

服务提供了多个Pod之间的负载均衡功能。
有一些常见的问题可以造成服务无法正常工作。以下说明将有助于调试服务的问题。

首先，验证服务是否有端点。对于每一个Service对像，apiserver使`endpoints`资源可用。

通过如下命令可以查看endpoints资源：

```shell
$ kubectl get endpoints ${SERVICE_NAME}
```

确保endpoints与服务内容器个数一致。
例如，如果你创建了一个nginx服务，它有3个副本，那么你就会在这个服务的endpoints中看到3个不同的IP地址。

#### 服务缺少endpoints

如果缺少endpoints，请尝试使用服务的labels列出所有的pod。
假如有一个服务，有如下的label：

```yaml
...
spec:
  - selector:
     name: nginx
     type: frontend
```

你可以使用如下命令列出与selector相匹配的pod，并验证这些pod是否归属于创建的服务：

```shell
$ kubectl get pods --selector=name=nginx,type=frontend
```

如果pod列表附合预期，但是endpoints仍然为空，那么可能没有暴露出正确的端口。
如果服务指定了`containerPort`，但是列表中的Pod没有列出该端口，则不会将其添加到端口列表。

验证该pod的`containerPort`与服务的`containerPort`是否匹配。

#### 网络业务不工作

如果可以连接到服务上，但是连接立即被断开了，并且在endpoints列表中有endpoints，可能是代理和pods之间不通。

确认以下3件事情：

-   Pods工作是否正常？ 看一下重启计数，并参阅[Debugging Pods](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/debug-application/#debugging-pods)；
-   可以直接连接到pod上吗？获取pod的IP地址，然后尝试直接连接到该IP上；
-   应用是否在配置的端口上进行服务？Kubernetes不进行端口重映射，所以如果应用在8080端口上服务，那么`containerPort`字段就需要设定为8080。

#### 更多信息

如果上述都不能解决你的问题，请按照[Debugging Service document](https://kubernetes.io/docs/user-guide/debugging-services)中的介绍来确保你的`Service`处于running态，有`Endpoints`，`Pods`真正的在服务；你有DNS在工作，安装了iptables规则，kube-proxy也没有异常行为。

你也可以访问[troubleshooting document](https://kubernetes.io/docs/troubleshooting/)来获取更多信息。





## 集群故障排查

本篇文档是介绍集群故障排查的；我们假设对于你碰到的问题，你已经排除了是由应用程序造成的。
对于应用的调试，请参阅[应用故障排查指南](https://kubernetes.io/cn/docs/tasks/debug-application-cluster/debug-application)。 你也可以访问[troubleshooting document](https://kubernetes.io/docs/troubleshooting/)来获取更多的信息。

### 显示出集群的节点列表

调试的第一步是查看所有的节点是否都正确的注册。

运行

```shell
kubectl get nodes
```

接下来，验证你的所有节点都能够显示出来，并且都处于`Ready`状态。

### 查看logs

现在，挖掘出集群更深层的信息就需要登录到相关的机器上。下面是相关log文件所在的位置。
(注意，对于基于systemd的系统，你可能需要使用`journalctl`)

### Master

-   /var/log/kube-apiserver.log - API Server, 提供API服务
-   /var/log/kube-scheduler.log - Scheduler, 负责调度决策
-   /var/log/kube-controller-manager.log - 管理replication controllers的控制器

Worker Nodes

-   /var/log/kubelet.log - Kubelet, 管控节点上运行的容器
-   /var/log/kube-proxy.log - Kube Proxy, 负责服务的负载均衡

### 集群故障模式的概述

下面是一个不完整的列表，列举了一些可能出错的场景，以及通过调整集群配置来解决相关问题的方法。

根本原因：

-   VM(s)关机
-   集群之间，或者集群和用户之间网络分裂
-   Kubernetes软件本身崩溃了
-   数据丢失或者持久化存储不可用(如:GCE PD 或 AWS EBS卷)
-   操作错误，如：Kubernetes或者应用程序配置错误

具体情况:

-   Apiserver所在的VM关机或者apiserver崩溃
    -   结果
        -   不能停止，更新，或者启动新的pods，services，replication controller
        -   现有的pods和services在不依赖Kubernetes API的情况下应该能继续正常工作
-   Apiserver 后端存储丢失
    -   结果
        -   apiserver应该不能起来
        -   kubelets将不能访问它，但是能够继续运行之前的Pods和提供相同的服务代理
        -   在apiserver重启之前，需要手动恢复或者重创apiserver的状态
-   Kubernetes服务组件(节点控制器，副本控制器，调度器等等)所在的VM关机或者崩溃
    -   当前，这些控制器是和apiserver共存的，它们不可用的现象是与apiserver类似的
    -   将来，这些控制器也会复制为多份，并且可能为非共存的
    -   它们没有自己的持久状态
-   单个节点(VM或者物理机)关机
    -   结果
        -   此节点上的所有Pods都停止运行
-   网络分裂(Network partition)
    -   结果
        -   partition A认为partition B中所有的节点都down掉了；partition B认为apiserver是down掉了(假定master所在的VM位于partition A内)。
-   Kubelet软件故障
    -   结果
        -   崩溃的kubelet就不能在其所在的节点上启动新的pods
        -   kubelet可能删掉pods或者不删
        -   节点被标识为非健康态
        -   副本控制器会在其它的节点上启动新的pods
-   集群操作错误
    -   结果
        -   丢失pods，服务等等
        -   丢失apiserver后端存储
        -   用户无法读取API
        -   等等

缓解措施:

-   措施：对于IaaS上的VMs，使用IaaS的自动VM重启功能
    -   缓解：Apiserver VM关机或apiserver崩溃
    -   缓解：Kubernetes服务组件所在的VM关机或崩溃
-   措施: 对于具有apiserver+etcd的VM，使用IaaS提供的可靠的存储（例如GCE PD或者AWS EBS卷）
    -   缓解：Apiserver后端存储的丢失
-   措施：使用（实验）[高可用性](https://kubernetes.io/docs/admin/high-availability)的配置
    -   缓解：master VM关机或者master组件(scheduler, API server, controller-managing)崩馈
    -   将容许一个或多个节点或组件同时出现故障
    -   缓解：apiserver后端存储(例如etcd的数据目录)丢失
    -   假定你使用了集群化的etcd。
-   措施：定期的对apiserver的PDs/EBS卷进行快照
    -   缓解：apiserver后端存储丢失
    -   缓解：一些操作错误的场景
    -   缓解：一些Kubernetes软件本身故障的场景
-   措施：在pods的前面使用副本控制器或服务
    -   缓解：节点关机
    -   缓解：Kubelet软件故障
-   措施：应用（容器）设计成容许异常重启
    -   缓解：节点关机
    -   缓解：Kubelet软件故障
-   措施：[多个独立的集群](https://kubernetes.io/docs/admin/multi-cluster)(并且避免一次性地对所有的集群进行有风险性的修改)
    -   缓解：以上列出的所有情况







## 故障排查

有时候事情会出错。本指南旨在正确解决这些问题。它包含两个部分：

-   [应用排错](https://v1-14.docs.kubernetes.io/docs/tasks/debug-application-cluster/debug-application/) - 用于部署代码到 Kubernetes 并想知道代码为什么不能正常运行的用户。
-   [集群排错](https://v1-14.docs.kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/) - 用于集群管理员以及 Kubernetes 集群表现异常的用户。

您也应该查看所用[版本](https://github.com/kubernetes/kubernetes/releases)的已知问题。

### 获取帮助

如果您的问题在上述指南中没有得到答案，您还有另外几种方式从 Kubernetes 团队获得帮助。

#### 提问

网站上的文档针对回答各类问题进行了结构化组织和分类。 [概念](https://v1-14.docs.kubernetes.io/docs/concepts/)部分解释了 Kubernetes 体系结构以及每个组件的工作方式，[安装](https://v1-14.docs.kubernetes.io/docs/setup/)部分提供了入门的实用说明。 [任务](https://v1-14.docs.kubernetes.io/docs/tasks/)部分展示了如何完成常用任务，[入门](https://v1-14.docs.kubernetes.io/docs/tutorials/)部分则是对现实世界、特定行业或端到端开发场景的更全面的演练。 [参考](https://v1-14.docs.kubernetes.io/docs/reference/)部分提供了详细的 [Kubernetes API](https://v1-14.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.14/) 文档和命令行 (CLI) 接口，例如[`kubectl`](https://v1-14.docs.kubernetes.io/docs/user-guide/kubectl-overview/)。

您还可以找到堆栈溢出相关的主题：

-   [Kubernetes](http://stackoverflow.com/questions/tagged/kubernetes)
-   [Google Kubernetes Engine](http://stackoverflow.com/questions/tagged/google-container-engine)

### 求救！我的问题还没有解决！我需要立即得到帮助！

#### StackOverFlow

社区中的其他人可能已经问过和您类似的问题，这或许能帮助解决您的问题。 Kubernetes 团队还会监视[带有 Kubernetes 标签的帖子](http://stackoverflow.com/questions/tagged/kubernetes)。 如果现有的问题对您没有帮助，请[问一个新问题](http://stackoverflow.com/questions/ask?tags=kubernetes)!

#### Slack

Kubernetes 团队在 Slack 中建有 `#kubernetes-users` 频道。 您可以[在这里](https://kubernetes.slack.com/)参加与 Kubernetes 团队的讨论。 Slack 需要注册，但 Kubernetes 团队公开邀请任何人[在这里](http://slack.kubernetes.io/)注册。 欢迎您随时来问任何问题。

一旦注册完成，您就可以浏览各种感兴趣的频道列表。 例如，Kubernetes 新人可能还想加入 `#kubernetes-novice` 频道。作为另一个例子，开发人员应该加入 `#kubernetes-dev` 频道。

还有许多国家/地区语言频道。请随时加入这些频道以获得本地化支持和信息：

-   中国： `#cn-users`, `#cn-events`
-   法国： `#fr-users`, `#fr-events`
-   德国： `#de-users`, `#de-events`
-   印度： `#in-users`, `#in-events`
-   意大利： `#it-users`, `#it-events`
-   日本： `#jp-users`, `#jp-events`
-   韩国： `#kr-users`
-   荷兰： `#nl-users`
-   挪威： `#norw-users`
-   波兰： `#pl-users`
-   俄罗斯： `#ru-users`
-   西班牙： `#es-users`
-   土耳其： `#tr-users`, `#tr-events`

#### 论坛

Kubernetes 官方论坛 [discuss.kubernetes.io](https://discuss.kubernetes.io/)

如果你发现一个看起来像 bug 的东西，或者你想提出一个功能请求，请使用[Github 问题跟踪系统](https://github.com/kubernetes/kubernetes/issues)。

在提交问题之前，请搜索现有问题以查看是否已涵盖您的问题。

如果提交 bug，请提供如何重现问题的详细信息，例如：

-   Kubernetes 版本：获取版本的命令为 `kubectl version`
-   云提供商，OS 发行版、网络配置和 Docker 版本
-   重现问题的步骤
